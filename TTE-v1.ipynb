{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 for Clustering: Target Trial Emulation\n",
    "- New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "- In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "1. Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "2. Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "2. Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "3. Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "4. Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "5. Do this by pair, preferably your thesis partner.\n",
    "6. Push to your github repository.\n",
    "7. Deadline is: February 28, 2025 at 11:59 pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import patsy\n",
    "import joblib\n",
    "import json\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import logit\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Class Definition and Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_glm_logit(save_path):\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    def fit_model(numerator, denominator, data):\n",
    "        formula = numerator\n",
    "        try:\n",
    "            model = smf.logit(formula, data).fit(disp=0)  # Suppress convergence messages\n",
    "        except (np.linalg.LinAlgError, sm.tools.sm_exceptions.PerfectSeparationError):\n",
    "            print(f\"Warning: Perfect separation or singular matrix detected for {formula}. Falling back to intercept-only model.\")\n",
    "            formula = f\"{formula.split('~')[0].strip()} ~ 1\"\n",
    "            model = smf.logit(formula, data).fit(disp=0)\n",
    "        model_path = os.path.join(save_path, \"logit_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "        model_details = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_type\": \"te_stats_glm_logit\",\n",
    "            \"file_path\": model_path\n",
    "        }\n",
    "        json.dump(model_details, open(os.path.join(save_path, \"model_details.json\"), \"w\"))\n",
    "        return model\n",
    "    \n",
    "    return fit_model\n",
    "\n",
    "@dataclass\n",
    "class TEDatastore:\n",
    "    data: pd.DataFrame = None\n",
    "\n",
    "    def save_expanded_data(self, switch_data: pd.DataFrame):\n",
    "        if self.data is None:\n",
    "            self.data = switch_data\n",
    "        else:\n",
    "            self.data = pd.concat([self.data, switch_data], ignore_index=True)\n",
    "        return self\n",
    "\n",
    "@dataclass\n",
    "class TEExpansion:\n",
    "    chunk_size: int = 0\n",
    "    datastore: TEDatastore = None\n",
    "    first_period: int = 0\n",
    "    last_period: float = float('inf')\n",
    "    censor_at_switch: bool = False\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand, **kwargs):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = None\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "        self.outcome_data = None\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        self.data[\"followup_time\"] = self.data.groupby(\"id\")[\"period\"].transform(\n",
    "            lambda x: x[(self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)].min()\n",
    "            if ((self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)).any()\n",
    "            else x.max()\n",
    "        )\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"Trial Sequence Object\\nEstimand: {self.estimand}\\n\")\n",
    "        if self.data is not None:\n",
    "            display(self.data)\n",
    "        else:\n",
    "            print(\"No data set\")\n",
    "        print(\"\\nIPW for informative censoring:\")\n",
    "        print(self.censor_weights if self.censor_weights is not None else \"Not calculated.\")\n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\nIPW for treatment switch censoring:\")\n",
    "            print(self.switch_weights)\n",
    "        print(\"\\nOutcome model:\")\n",
    "        print(self.outcome_model if self.outcome_model is not None else \"Not specified.\")\n",
    "        if self.outcome_data is not None:\n",
    "            print(\"\\nOutcome data:\")\n",
    "            print(self.outcome_data)\n",
    "\n",
    "    def set_switch_weight_model(self, numerator=None, denominator=None, model_fitter=None, eligible_wts_0=None, eligible_wts_1=None):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"set_data() before setting switch weight models\")\n",
    "        if self.estimand == \"ITT\":\n",
    "            raise ValueError(\"Switching weights are not supported for intention-to-treat analyses\")\n",
    "        if eligible_wts_0 and eligible_wts_0 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_0: \"eligible_wts_0\"})\n",
    "        if eligible_wts_1 and eligible_wts_1 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_1: \"eligible_wts_1\"})\n",
    "        if numerator is None:\n",
    "            numerator = \"1\"\n",
    "        if denominator is None:\n",
    "            denominator = \"1\"\n",
    "        if \"time_on_regime\" in denominator:\n",
    "            raise ValueError(\"time_on_regime should not be used in denominator.\")\n",
    "        formula_numerator = f\"treatment ~ {numerator}\"\n",
    "        formula_denominator = f\"treatment ~ {denominator}\"\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"model_fitter\": \"te_stats_glm_logit\",\n",
    "        }\n",
    "        if model_fitter is not None:\n",
    "            self.switch_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.switch_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_prob_0\"] = self.switch_weights[\"fitted_model_0_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.data[\"switch_prob_1\"] = self.switch_weights[\"fitted_model_1_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_weight\"] = np.where(self.data[\"previous_treatment\"] == 0, \n",
    "                                                  1 / self.data[\"switch_prob_0\"], \n",
    "                                                  1 / self.data[\"switch_prob_1\"])\n",
    "            self.data[\"switch_weight\"] = self.data[\"switch_weight\"].fillna(1)\n",
    "            print(\"Switch weights computed and stored in self.data\")\n",
    "\n",
    "    def show_switch_weights(self):\n",
    "        return self.switch_weights if self.switch_weights else \"Not calculated\"\n",
    "    \n",
    "    def show_censor_weights(self):\n",
    "        return self.censor_weights if self.censor_weights else \"Not calculated\"\n",
    "    \n",
    "    def set_censor_weight_model(self, censor_event, numerator=\"1\", denominator=\"1\", pool_models=\"none\", model_fitter=None):\n",
    "        if model_fitter is None:\n",
    "            model_fitter = stats_glm_logit()\n",
    "        if censor_event not in self.data.columns:\n",
    "            raise ValueError(f\"'{censor_event}' must be a column in the dataset.\")\n",
    "        self.data[\"censored_inv\"] = 1 - self.data[censor_event]\n",
    "        formula_numerator = f\"censored_inv ~ {numerator}\"\n",
    "        formula_denominator = f\"censored_inv ~ {denominator}\"\n",
    "        self.censor_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"pool_numerator\": pool_models in [\"numerator\", \"both\"],\n",
    "            \"pool_denominator\": pool_models == \"both\",\n",
    "            \"model_fitter\": \"te_stats_glm_logit\"\n",
    "        }\n",
    "        if self.estimand == \"PP\":\n",
    "            self.censor_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.censor_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "        elif self.estimand == \"ITT\":\n",
    "            self.censor_weights[\"fitted_model_numerator\"] = model_fitter(formula_numerator, denominator, self.data)\n",
    "            if not self.censor_weights[\"pool_denominator\"]:\n",
    "                self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "                self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "\n",
    "# STEP 4\n",
    "\n",
    "    def calculate_weights(self, quiet=False):\n",
    "        use_censor_weights = isinstance(self.censor_weights, dict) and (\n",
    "            \"fitted_model_0_denominator\" in self.censor_weights or \"fitted_model_numerator\" in self.censor_weights\n",
    "        )\n",
    "        if self.estimand == \"PP\":\n",
    "            if not (isinstance(self.switch_weights, dict) and \"fitted_model_0_denominator\" in self.switch_weights):\n",
    "                raise ValueError(\"Switch weight models are not specified. Use set_switch_weight_model()\")\n",
    "            self._calculate_weights_trial_seq(quiet, switch_weights=True, censor_weights=use_censor_weights)\n",
    "        elif self.estimand == \"ITT\":\n",
    "            self._calculate_weights_trial_seq(quiet, switch_weights=False, censor_weights=use_censor_weights)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown estimand: {self.estimand}\")\n",
    "\n",
    "    def _calculate_weights_trial_seq(self, quiet, switch_weights, censor_weights):\n",
    "        if switch_weights:\n",
    "            if not quiet:\n",
    "                print(\"Calculating switch weights...\")\n",
    "            switch_model_0 = self.switch_weights[\"fitted_model_0_denominator\"]\n",
    "            switch_model_1 = self.switch_weights[\"fitted_model_1_denominator\"]\n",
    "            mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "            mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "            self.data.loc[mask_0, \"switch_prob\"] = switch_model_0.predict(self.data[mask_0])\n",
    "            self.data.loc[mask_1, \"switch_prob\"] = switch_model_1.predict(self.data[mask_1])\n",
    "            self.data[\"switch_prob\"] = self.data[\"switch_prob\"].fillna(1.0)\n",
    "            self.data[\"switch_weight\"] = 1 / self.data[\"switch_prob\"]\n",
    "        if censor_weights:\n",
    "            if not quiet:\n",
    "                print(\"Calculating censor weights...\")\n",
    "            if self.estimand == \"PP\":\n",
    "                censor_model_0 = self.censor_weights[\"fitted_model_0_denominator\"]\n",
    "                censor_model_1 = self.censor_weights[\"fitted_model_1_denominator\"]\n",
    "                mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "                mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "                self.data.loc[mask_0, \"censor_prob\"] = censor_model_0.predict(self.data[mask_0])\n",
    "                self.data.loc[mask_1, \"censor_prob\"] = censor_model_1.predict(self.data[mask_1])\n",
    "            elif self.estimand == \"ITT\":\n",
    "                censor_model = self.censor_weights[\"fitted_model_numerator\"]\n",
    "                self.data[\"censor_prob\"] = censor_model.predict(self.data)\n",
    "            self.data[\"censor_prob\"] = self.data[\"censor_prob\"].fillna(1.0)\n",
    "            self.data[\"censor_weight\"] = 1 / self.data[\"censor_prob\"]\n",
    "        if switch_weights and censor_weights:\n",
    "            self.data[\"final_weight\"] = self.data[\"switch_weight\"] * self.data[\"censor_weight\"]\n",
    "        elif switch_weights:\n",
    "            self.data[\"final_weight\"] = self.data[\"switch_weight\"]\n",
    "        elif censor_weights:\n",
    "            self.data[\"final_weight\"] = self.data[\"censor_weight\"]\n",
    "        if \"switch_weight\" in self.data.columns:\n",
    "            print(\"\\nWeight Summary for PP:\")\n",
    "            print(self.data[[\"switch_weight\", \"censor_weight\", \"final_weight\"]].describe())\n",
    "        else:\n",
    "            print(\"\\nWeight Summary for ITT:\")\n",
    "            print(self.data[[\"censor_weight\", \"final_weight\"]].describe())\n",
    "\n",
    "    def show_weight_models(self):\n",
    "        if self.switch_weights is None and self.censor_weights is None:\n",
    "            print(\"No weight models have been set.\")\n",
    "            return\n",
    "\n",
    "        if self.estimand == \"PP\":\n",
    "            print(\"===== PP Estimand (No Pooling) =====\")\n",
    "            if self.censor_weights is not None:\n",
    "                print(\"\\n## Informative Censoring Weights ##\")\n",
    "                for prev_treatment in [0, 1]:\n",
    "                    for key in [\"numerator\", \"denominator\"]:\n",
    "                        model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                        if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                            print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                            print(self.censor_weights[model_key].summary())\n",
    "            \n",
    "            if self.switch_weights is not None:\n",
    "                print(\"\\n## Treatment Switch Weights ##\")\n",
    "                for prev_treatment in [0, 1]:\n",
    "                    for key in [\"numerator\", \"denominator\"]:\n",
    "                        model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                        if model_key in self.switch_weights and self.switch_weights[model_key] is not None:\n",
    "                            print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                            print(self.switch_weights[model_key].summary())\n",
    "        \n",
    "        elif self.estimand == \"ITT\":\n",
    "            print(\"===== ITT Estimand =====\")\n",
    "            if self.censor_weights is not None:\n",
    "                print(\"\\n## Informative Censoring Weights ##\")\n",
    "                if \"fitted_model_numerator\" in self.censor_weights and self.censor_weights[\"fitted_model_numerator\"] is not None:\n",
    "                    print(\"\\n# Numerator Model (Pooled)\")\n",
    "                    print(self.censor_weights[\"fitted_model_numerator\"].summary())\n",
    "                for prev_treatment in [0, 1]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_denominator\"\n",
    "                    if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                        print(f\"\\n# Denominator Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.censor_weights[model_key].summary())\n",
    "\n",
    "#STEP 5\n",
    "    def set_outcome_model(self, adjustment_terms=None, model_fitter=None):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"set_data() before defining the outcome model.\")\n",
    "\n",
    "        # Determine treatment variable\n",
    "        treatment_var = \"treatment\"\n",
    "\n",
    "        # Extract stabilized weight terms\n",
    "        stabilised_weight_terms = []\n",
    "        if self.switch_weights:\n",
    "            stabilised_weight_terms.append(self.switch_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "        if self.censor_weights:\n",
    "            stabilised_weight_terms.append(self.censor_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "\n",
    "        stabilised_weight_terms = \" + \".join(stabilised_weight_terms) if stabilised_weight_terms else \"1\"\n",
    "\n",
    "        # Default adjustment terms based on estimand\n",
    "        if adjustment_terms is None:\n",
    "            adjustment_terms = [\"x1\", \"x2\", \"x3\", \"age\"] if self.estimand == \"PP\" else [\"x2\"]\n",
    "        elif isinstance(adjustment_terms, str):\n",
    "            adjustment_terms = adjustment_terms.split(\" + \")\n",
    "\n",
    "        # Polynomial terms for time effects\n",
    "        additional_terms = []\n",
    "        if \"followup_time\" in self.data.columns:\n",
    "            self.data[\"followup_time_squared\"] = self.data[\"followup_time\"] ** 2\n",
    "            additional_terms.extend([\"followup_time\", \"followup_time_squared\"])\n",
    "\n",
    "        # Ensure 'period' and its squared term are included\n",
    "        if \"period\" in self.data.columns:\n",
    "            self.data[\"period_squared\"] = self.data[\"period\"] ** 2\n",
    "            additional_terms.extend([\"period\", \"period_squared\"])\n",
    "\n",
    "        # Ensure unique terms using a set\n",
    "        all_terms = set([treatment_var] + adjustment_terms + additional_terms)\n",
    "        stabilised_terms = set(stabilised_weight_terms.split(\" + \"))  # Convert to set\n",
    "\n",
    "        # Merge while keeping unique terms\n",
    "        final_terms = all_terms | stabilised_terms\n",
    "        final_terms.discard(\"1\")  # Remove placeholder \"1\" if present\n",
    "\n",
    "        # Construct formula\n",
    "        formula = \"outcome ~ \" + \" + \".join(sorted(final_terms))  # Sort for consistency\n",
    "\n",
    "        # Ensure weights exist\n",
    "        if \"final_weight\" not in self.data.columns:\n",
    "            raise ValueError(\"Weights have not been calculated. Run calculate_weights() first.\")\n",
    "\n",
    "        # Default to logistic regression model fitter if none is provided\n",
    "        if model_fitter is None:\n",
    "            model_fitter = stats_glm_logit(save_path=None)\n",
    "\n",
    "        # Store in outcome_model dictionary\n",
    "        self.outcome_model = {\n",
    "            \"formula\": formula,\n",
    "            \"treatment_var\": treatment_var,\n",
    "            \"adjustment_vars\": list(all_terms),  # Store as list for consistency\n",
    "            \"stabilised_weights_terms\": \" + \".join(sorted(stabilised_terms)),  # Keep as string for logging\n",
    "            \"model_fitter\": model_fitter,\n",
    "            \"fitted\": None  # Will be used in Step 8 (fit_msm)\n",
    "        }\n",
    "\n",
    "        return self\n",
    "\n",
    "    def show_outcome_model(self):\n",
    "        return self.outcome_model if self.outcome_model else \"Not calculated\"\n",
    "    \n",
    "\n",
    "#STEP 6\n",
    "    def set_expansion_options(self, output: TEDatastore, chunk_size: int = 0, first_period: int = 0, last_period: float = float('inf'), censor_at_switch: bool = False):\n",
    "        \n",
    "        self.expansion = TEExpansion(chunk_size = chunk_size, datastore = output, first_period = first_period, last_period = last_period, censor_at_switch = censor_at_switch)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def expand_trials(self):\n",
    "        data = self.data.copy()\n",
    "        outcome_adj_vars = self.get_outcome_adjustment_vars()\n",
    "        keeplist = list(set(['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2', 'age'] + outcome_adj_vars))\n",
    "\n",
    "        if 'wt' not in data.columns:\n",
    "            data['wt'] = 1\n",
    "\n",
    "        all_ids = data['id'].unique()\n",
    "        if self.expansion.chunk_size == 0:\n",
    "            ids_split = [all_ids]\n",
    "        else:\n",
    "            ids_split = np.array_split(all_ids, np.ceil(len(all_ids) / self.expansion.chunk_size))\n",
    "\n",
    "        for ids in ids_split:\n",
    "            switch_data = self._expand_chunk(data, ids, outcome_adj_vars, keeplist)\n",
    "            self.expansion.datastore = self.expansion.datastore.save_expanded_data(switch_data)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _expand_chunk(self, data: pd.DataFrame, ids: np.ndarray, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "        chunk_data = data[data['id'].isin(ids)].copy()\n",
    "\n",
    "        first_period = max([self.expansion.first_period, chunk_data[chunk_data['eligible'] == 1]['period'].min() or self.expansion.first_period])\n",
    "        last_period = min([self.expansion.last_period, chunk_data[chunk_data['eligible'] == 1]['period'].max() or self.expansion.last_period])\n",
    "        \n",
    "        expanded_data = []\n",
    "        for _, row in chunk_data.iterrows():\n",
    "            if row['eligible'] == 1 and first_period <= row['period'] <= last_period:\n",
    "                trial_start = row['period']\n",
    "                trial_data = self._generate_trial_instance(row, chunk_data, trial_start, last_period, outcome_adj_vars, keeplist)\n",
    "                expanded_data.append(trial_data)\n",
    "\n",
    "        result = pd.concat(expanded_data, ignore_index=True) if expanded_data else pd.DataFrame()\n",
    "\n",
    "        return result[keeplist]\n",
    "    \n",
    "\n",
    "    def _generate_trial_instance(self, baseline_row: pd.Series, data: pd.DataFrame, trial_start: int, last_period: float, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "\n",
    "        id_val = baseline_row['id']\n",
    "        patient_data = data[data['id'] == id_val].sort_values('period')\n",
    "        rows = []\n",
    "\n",
    "        if pd.isna(last_period) or last_period == float('inf'):\n",
    "            last_period_value = patient_data['period'].max()\n",
    "        else:\n",
    "            last_period_value = last_period\n",
    "\n",
    "        # Convert float to integer to handle errors\n",
    "        if pd.notna(last_period_value):\n",
    "            last_period_int = int(np.floor(float(last_period_value)))\n",
    "        else:\n",
    "            last_period_int = int(trial_start)\n",
    "\n",
    "        max_period_value = patient_data['period'].max()\n",
    "        if pd.notna(max_period_value):\n",
    "            max_period = int(np.floor(float(max_period_value)))\n",
    "        else:\n",
    "            max_period = last_period_int \n",
    "\n",
    "        last_period_int = int(last_period_int)\n",
    "        max_period = int(max_period)\n",
    "\n",
    "        for period in range(int(trial_start), int(min(last_period_int + 1, max_period + 1))):\n",
    "            period_row = patient_data[patient_data['period'] == period].iloc[0] if not patient_data[patient_data['period'] == period].empty else None\n",
    "            \n",
    "            if period_row is None:\n",
    "                continue\n",
    "\n",
    "            if self.expansion.censor_at_switch and period > trial_start:\n",
    "                prev_row = patient_data[patient_data['period'] == (period - 1)].iloc[0]\n",
    "                if prev_row['treatment'] != period_row['treatment']:\n",
    "                    break  # Censor at switch\n",
    "\n",
    "            trial_period = period - trial_start\n",
    "            followup_time = period - trial_start\n",
    "            final_weight = self.data[(self.data['id'] == id_val) & (self.data['period'] == period)]['final_weight'].iloc[0] if not self.data[(self.data['id'] == id_val) & (self.data['period'] == period)].empty else 1.0\n",
    "            row_dict = {\n",
    "                'id': id_val,\n",
    "                'trial_period': trial_period,\n",
    "                'followup_time': followup_time,\n",
    "                'outcome': period_row['outcome'],\n",
    "                'weight': final_weight,  \n",
    "                'treatment': period_row['treatment'],\n",
    "            }\n",
    "            \n",
    "            for var in outcome_adj_vars + ['age', 'x2']:\n",
    "                if var in patient_data.columns:\n",
    "                    row_dict[var] = period_row.get(var, np.nan)\n",
    "                else:\n",
    "                    row_dict[var] = np.nan \n",
    "\n",
    "            rows.append(pd.Series(row_dict))\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        int_columns = ['id', 'trial_period', 'followup_time', 'outcome', 'treatment', 'age']\n",
    "        df[int_columns] = df[int_columns].astype(int)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_outcome_adjustment_vars(self):\n",
    "        return getattr(self.outcome_model, 'adjustment_vars', [])\n",
    "    \n",
    "\n",
    "# STEP 7\n",
    "    def load_expanded_data(self, p_control: Optional[float] = None, period: Optional[List[int]] = None, subset_condition: Optional[str] = None, seed: Optional[int] = None):\n",
    "        \n",
    "        if p_control is None:\n",
    "            data_table = self.expansion.datastore.data.copy()\n",
    "            data_table['sample_weight'] = 1\n",
    "        else:\n",
    "            np.random.seed(seed) if seed is not None else np.random.seed()\n",
    "            data_table = self.expansion.datastore.data.copy()\n",
    "\n",
    "            mask_outcome_1 = data_table['outcome'] == 1\n",
    "            mask_outcome_0 = data_table['outcome'] == 0\n",
    "            sampled_0 = data_table[mask_outcome_0].sample(frac=p_control, replace=False)\n",
    "            data_table = pd.concat([data_table[mask_outcome_1], sampled_0])\n",
    "\n",
    "            data_table.loc[mask_outcome_0, 'sample_weight'] = 1 / p_control if p_control > 0 else 1\n",
    "            data_table.loc[mask_outcome_1, 'sample_weight'] = 1\n",
    "\n",
    "        if period is not None:\n",
    "            data_table = data_table[data_table['trial_period'].isin(period) | data_table['followup_time'].isin(period)]\n",
    "        \n",
    "        if subset_condition is not None:\n",
    "            data_table = data_table.query(subset_condition)\n",
    "        \n",
    "        data_table = data_table.sort_values(['id', 'trial_period', 'followup_time'])\n",
    "        data_table = data_table.reset_index(drop=True)\n",
    "        \n",
    "        self.outcome_data = data_table\n",
    "        \n",
    "        return self\n",
    "    \n",
    "# STEP 8\n",
    "    def fit_msm(self, weight_cols=[\"final_weight\"], modify_weights=None, family=\"binomial\"):\n",
    "        if not self.outcome_model:\n",
    "            raise ValueError(\"Outcome model not defined. Run set_outcome_model() first.\")\n",
    "        \n",
    "        formula = self.outcome_model[\"formula\"]\n",
    "        print(f\"Using formula from set_outcome_model: {formula}\")\n",
    "        \n",
    "        weight_col = next(col for col in weight_cols if col in self.data.columns)\n",
    "        data = self.data[~self.data[weight_col].isna()].copy()\n",
    "        weights = data[weight_col].values\n",
    "        \n",
    "        if modify_weights:\n",
    "            weights = modify_weights(weights)\n",
    "        \n",
    "        # Fit the MSM\n",
    "        try:\n",
    "            if family == \"binomial\":\n",
    "                model = smf.logit(formula, data=data)\n",
    "                fitted_model = model.fit(method='lbfgs', weights=weights, disp=0, maxiter=100)\n",
    "            elif family == \"gaussian\":\n",
    "                model = smf.ols(formula, data=data, weights=weights)\n",
    "                fitted_model = model.fit()\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported family. Use 'binomial' or 'gaussian'.\")\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            raise ValueError(f\"Model fitting failed due to singular matrix: {e}.\")\n",
    "        \n",
    "        print(\"MSM Fit Summary:\")\n",
    "        print(fitted_model.summary())\n",
    "        self.outcome_model[\"fitted\"] = fitted_model\n",
    "        return fitted_model\n",
    "\n",
    "# STEP 9\n",
    "    def predict(self, newdata=None, predict_times=None, type=\"survival\", confidence_level=0.95):\n",
    "        \n",
    "        if not self.outcome_model or self.outcome_model[\"fitted\"] is None:\n",
    "            raise ValueError(\"MSM not fitted. Run fit_msm() first.\")\n",
    "        \n",
    "        # Use outcome_data if newdata is not provided\n",
    "        if newdata is None:\n",
    "            if self.outcome_data is None:\n",
    "                raise ValueError(\"outcome_data not available. Run load_expanded_data() first.\")\n",
    "            newdata = self.outcome_data[self.outcome_data[\"trial_period\"] == 1].copy()\n",
    "        else:\n",
    "            newdata = newdata[newdata[\"trial_period\"] == 1].copy()\n",
    "        \n",
    "        # Default predict_times if not specified\n",
    "        if predict_times is None:\n",
    "            predict_times = np.arange(0, 11)\n",
    "        \n",
    "        # Ensure predict_times are integers and within data range\n",
    "        predict_times = np.array(predict_times, dtype=int)\n",
    "        max_time = newdata[\"followup_time\"].max()\n",
    "        predict_times = predict_times[predict_times <= max_time]\n",
    "        \n",
    "        # Extract fitted model\n",
    "        fitted_model = self.outcome_model[\"fitted\"]\n",
    "        \n",
    "        # Prepare data for prediction\n",
    "        prediction_data = []\n",
    "        treatment_values = [0, 1]  # Assume binary treatment\n",
    "        for time in predict_times:\n",
    "            for treatment in treatment_values:\n",
    "                temp_data = newdata.copy()\n",
    "                temp_data[\"followup_time\"] = time\n",
    "                temp_data[\"treatment\"] = treatment\n",
    "                # Update other time-dependent terms if needed (e.g., period, period_squared)\n",
    "                temp_data[\"period\"] = time + 1  # Adjust based on your data structure\n",
    "                temp_data[\"period_squared\"] = temp_data[\"period\"] ** 2\n",
    "                temp_data[\"followup_time_squared\"] = temp_data[\"followup_time\"] ** 2\n",
    "                \n",
    "                # Predict probabilities\n",
    "                pred_prob = fitted_model.predict(temp_data)\n",
    "                prediction_data.append({\n",
    "                    \"followup_time\": time,\n",
    "                    \"treatment\": treatment,\n",
    "                    \"predicted_prob\": pred_prob.mean()  # Average over individuals\n",
    "                })\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        pred_df = pd.DataFrame(prediction_data)\n",
    "        \n",
    "        # Calculate survival (1 - cumulative probability, approximated)\n",
    "        # Note: This is a simplification; true survival requires time-to-event modeling\n",
    "        pred_df[\"survival\"] = 1 - pred_df[\"predicted_prob\"]\n",
    "        \n",
    "        # Group by time for treatment 0 and 1\n",
    "        surv_0 = pred_df[pred_df[\"treatment\"] == 0].set_index(\"followup_time\")[\"survival\"]\n",
    "        surv_1 = pred_df[pred_df[\"treatment\"] == 1].set_index(\"followup_time\")[\"survival\"]\n",
    "        \n",
    "        # Calculate difference and confidence intervals\n",
    "        difference = surv_1 - surv_0\n",
    "        conf_int = fitted_model.conf_int(alpha=1 - confidence_level)\n",
    "        # Approximate CI for difference (simplified; actual CI requires bootstrapping or delta method)\n",
    "        se = np.sqrt((fitted_model.bse ** 2).sum())  # Rough standard error approximation\n",
    "        z_score = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "        ci_lower = difference - z_score * se\n",
    "        ci_upper = difference + z_score * se\n",
    "        \n",
    "        result = {\n",
    "            \"survival\": {\n",
    "                \"followup_time\": surv_0.index,\n",
    "                \"treatment_0\": surv_0.values,\n",
    "                \"treatment_1\": surv_1.values\n",
    "            },\n",
    "            \"difference\": {\n",
    "                \"followup_time\": difference.index,\n",
    "                \"survival_diff\": difference.values,\n",
    "                f\"{int(100 * (1 - confidence_level) / 2)}%\": ci_lower,\n",
    "                f\"{int(100 * (1 + confidence_level))}%\": ci_upper\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if type == \"difference\":\n",
    "            return result[\"difference\"]\n",
    "        return result\n",
    "#Subclass of Trial Sequence, handles the PP (hehe) estimand\n",
    "class TrialSequencePP(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"PP\", **kwargs)\n",
    " \n",
    "#Subclass of Trial Sequence, handles the ITT estimand\n",
    "class TrialSequenceITT(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"ITT\", **kwargs)\n",
    "\n",
    "#trial_sequence function equivalent used in the article\n",
    "def trial_sequence(estimand, **kwargs):\n",
    "    estimand_classes = {\n",
    "        \"PP\": TrialSequencePP,\n",
    "        \"ITT\": TrialSequenceITT\n",
    "    }\n",
    "\n",
    "    if estimand not in estimand_classes:\n",
    "        raise ValueError(f\"{estimand} is not a valid estimand, choose either PP or ITT\")\n",
    "    \n",
    "    return estimand_classes[estimand](**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "A sequence of target trials analysis starts by specifying which estimand will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_pp = trial_sequence(\"PP\")\n",
    "trial_itt = trial_sequence(\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Dummy Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  \n",
       "0          0         0         1  \n",
       "1          0         0         0  \n",
       "2          0         0         0  \n",
       "3          0         0         0  \n",
       "4          0         0         0  \n",
       "..       ...       ...       ...  \n",
       "720        0         0         0  \n",
       "721        0         0         0  \n",
       "722        0         0         0  \n",
       "723        0         0         0  \n",
       "724        1         0         0  \n",
       "\n",
       "[725 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: PP\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n",
      "Trial Sequence Object\n",
      "Estimand: ITT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Extracted Dummy Data\")\n",
    "display(data_censored)\n",
    "data_censored[\"previous_treatment\"] = data_censored[\"treatment\"].shift(1).fillna(0)\n",
    "#Setting the dataset to the data field\n",
    "trial_pp.set_data(data_censored.copy())  # Create a separate copy\n",
    "trial_itt.set_data(data_censored.copy())  \n",
    "\n",
    "\n",
    "#Displaying the info stored in each class\n",
    "trial_pp.show()\n",
    "\n",
    "trial_itt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Weight Models\n",
    "To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. To estimate these weights, we construct time-to-(censoring) event models. Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring.\n",
    "#### 3.1 Censoring due to treatment switching\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch weights computed and stored in self.data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'numerator': 'treatment ~ age',\n",
       " 'denominator': 'treatment ~ age + x1 + x3',\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d273e9790>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28dad0d0>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28d26150>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28d25910>}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Models\"\n",
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_switch_weight_model(numerator=\"age\", denominator=\"age + x1 + x3\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"switch_models\")))\n",
    "trial_pp.show_switch_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Other informative censoring\n",
    "In case there is other informative censoring occurring in the data, we can create similar models to estimate the IPCW. These can be used with all types of estimand. We need to specifycensor_event which is the column containing the censoring indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': False,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28dad3d0>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28e8c770>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28e8d670>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28d622d0>}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"none\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_pp.show_censor_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': True,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28dae510>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28e8ef90>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28d74d70>}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 1]\n",
    "trial_itt.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"numerator\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_itt.show_censor_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate Weights\n",
    "Next we need to fit the individual models and combine them into weights. This is done with calculate_weights()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating switch weights...\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for PP:\n",
      "       switch_weight  censor_weight  final_weight\n",
      "count     725.000000     725.000000    725.000000\n",
      "mean        2.733546       1.090906      3.030777\n",
      "std         1.732471       0.070613      2.072097\n",
      "min         1.246125       1.013764      1.329844\n",
      "25%         1.620576       1.048496      1.739213\n",
      "50%         1.955091       1.068877      2.120418\n",
      "75%         3.258089       1.107154      3.581826\n",
      "max        12.525849       1.614490     13.890368\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for ITT:\n",
      "       censor_weight  final_weight\n",
      "count     725.000000    725.000000\n",
      "mean        1.088628      1.088628\n",
      "std         0.044576      0.044576\n",
      "min         1.019809      1.019809\n",
      "25%         1.060133      1.060133\n",
      "50%         1.080359      1.080359\n",
      "75%         1.107915      1.107915\n",
      "max         1.499109      1.499109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trial_pp.calculate_weights()\n",
    "trial_itt.calculate_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PP Estimand (No Pooling) =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02782\n",
      "Time:                        16:07:43   Log-Likelihood:                -116.34\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.009874\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.3297      0.185     12.625      0.000       1.968       2.691\n",
      "x2            -0.4692      0.184     -2.547      0.011      -0.830      -0.108\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        16:07:43   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02072\n",
      "Time:                        16:07:43   Log-Likelihood:                -79.752\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06621\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6180      0.222     11.796      0.000       2.183       3.053\n",
      "x2            -0.3903      0.210     -1.859      0.063      -0.802       0.021\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        16:07:43   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n",
      "\n",
      "## Treatment Switch Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.05496\n",
      "Time:                        16:07:43   Log-Likelihood:                -232.41\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.001e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7138      0.487      3.520      0.000       0.760       2.668\n",
      "age           -0.0488      0.010     -4.990      0.000      -0.068      -0.030\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      382\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07371\n",
      "Time:                        16:07:43   Log-Likelihood:                -227.80\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.609e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6569      0.520      3.185      0.001       0.637       2.676\n",
      "age           -0.0526      0.010     -5.236      0.000      -0.072      -0.033\n",
      "x1             0.6504      0.230      2.825      0.005       0.199       1.102\n",
      "x3            -0.2106      0.228     -0.923      0.356      -0.658       0.237\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                0.009356\n",
      "Time:                        16:07:43   Log-Likelihood:                -223.10\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04009\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4232      0.475      2.995      0.003       0.492       2.355\n",
      "age           -0.0204      0.010     -2.040      0.041      -0.040      -0.001\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      335\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02034\n",
      "Time:                        16:07:43   Log-Likelihood:                -220.62\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02721\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.0572      0.520      2.033      0.042       0.038       2.077\n",
      "age           -0.0180      0.010     -1.762      0.078      -0.038       0.002\n",
      "x1             0.5117      0.257      1.995      0.046       0.009       1.014\n",
      "x3             0.2281      0.230      0.992      0.321      -0.223       0.679\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_pp.show_weight_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ITT Estimand =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Pooled)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        16:07:43   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.4481      0.141     17.415      0.000       2.173       2.724\n",
      "x2            -0.4486      0.137     -3.278      0.001      -0.717      -0.180\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        16:07:43   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        16:07:43   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_itt.show_weight_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Specify Outcome Model\n",
    "Now we can specify the outcome model. Here we can include adjustment terms for any variables in the dataset. The numerator terms from the stabilised weight models are automatically included in the outcome model formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': 'outcome ~ age + followup_time + followup_time_squared + period + period_squared + treatment + x1 + x2 + x3',\n",
       " 'treatment_var': 'treatment',\n",
       " 'adjustment_vars': ['x1',\n",
       "  'age',\n",
       "  'x3',\n",
       "  'treatment',\n",
       "  'followup_time',\n",
       "  'followup_time_squared',\n",
       "  'period_squared',\n",
       "  'x2',\n",
       "  'period'],\n",
       " 'stabilised_weights_terms': 'age + x2',\n",
       " 'model_fitter': <function __main__.stats_glm_logit.<locals>.fit_model(numerator, denominator, data)>,\n",
       " 'fitted': None}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_pp.set_outcome_model()  \n",
    "trial_itt.set_outcome_model(adjustment_terms=\"x2\")  \n",
    "trial_pp.show_outcome_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expand Trials\n",
    "Now we are ready to create the data set with all of the sequence of target trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x26d275d5fd0>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = TEDatastore()\n",
    "trial_pp.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = True)\n",
    "trial_itt.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Create Sequence of Trials Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanded Data:\n",
      "     id    weight  age  treatment  followup_time  outcome  trial_period  \\\n",
      "0     1  1.792166   36          1              0        0             0   \n",
      "1     1  1.508792   37          1              1        0             1   \n",
      "2     1  1.788880   38          1              2        0             2   \n",
      "3     1  1.823548   39          1              3        0             3   \n",
      "4     1  1.542038   40          1              4        0             4   \n",
      "..   ..       ...  ...        ...            ...      ...           ...   \n",
      "995  98  1.161473   64          1              0        0             0   \n",
      "996  98  1.056842   65          1              1        0             1   \n",
      "997  98  1.062165   66          1              2        0             2   \n",
      "998  99  1.074015   65          1              0        0             0   \n",
      "999  99  1.052628   66          1              1        0             1   \n",
      "\n",
      "           x2  \n",
      "0    1.146148  \n",
      "1    0.002200  \n",
      "2   -0.481762  \n",
      "3    0.007872  \n",
      "4    0.216054  \n",
      "..        ...  \n",
      "995  1.392339  \n",
      "996 -0.934798  \n",
      "997 -0.735241  \n",
      "998 -0.346378  \n",
      "999 -1.106481  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "trial_pp.expand_trials()\n",
    "trial_itt.expand_trials()\n",
    "print(\"\\nExpanded Data:\")\n",
    "print(trial_itt.expansion.datastore.data)\n",
    "trial_pp.expansion.datastore.data.to_csv(\"outputfor_pp.csv\", index=False)\n",
    "trial_itt.expansion.datastore.data.to_csv(\"outputfor_itt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load or Sample Expanded Data\n",
    "Now that the expanded data has been created, we can prepare the data to fit the outcome model. For data that can fit comfortably in memory, this is a trivial step using load_expanded_data.\n",
    "\n",
    "For large datasets, it may be necessary to sample from the expanded by setting the p_control argument. This sets the probability that an observation with outcome == 0 will be included in the loaded data. A seed can be set for reproducibility. Additionally, a vector of periods to include can be specified, e.g., period = 1:60, and/or a subsetting condition, subset_condition = \"age > 65\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x26d275d5fd0>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_pp.load_expanded_data(p_control = 0.5, seed=1234)\n",
    "trial_itt.load_expanded_data(p_control = 0.5, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fit Marginal Structural Model\n",
    "To fit the outcome model we use fit_msm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using formula from set_outcome_model: outcome ~ followup_time + followup_time_squared + period + period_squared + treatment + x2\n",
      "MSM Fit Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      718\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                  0.5157\n",
      "Time:                        16:07:45   Log-Likelihood:                -27.599\n",
      "converged:                       True   LL-Null:                       -56.987\n",
      "Covariance Type:            nonrobust   LLR p-value:                 7.976e-11\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.7302      0.859     -3.180      0.001      -4.413      -1.047\n",
      "followup_time            -0.8903   2.72e+04  -3.28e-05      1.000   -5.32e+04    5.32e+04\n",
      "followup_time_squared    -6.6018   2.72e+04     -0.000      1.000   -5.32e+04    5.32e+04\n",
      "period                    1.4261   2.72e+04   5.25e-05      1.000   -5.32e+04    5.32e+04\n",
      "period_squared            6.5719   2.72e+04      0.000      1.000   -5.32e+04    5.32e+04\n",
      "treatment                -0.7385      0.775     -0.953      0.341      -2.258       0.781\n",
      "x2                        0.0144      0.357      0.040      0.968      -0.684       0.713\n",
      "=========================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.88 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "c:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x26d28cc35f0>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def winsorize_weights(weights):\n",
    "    #99th percentile values\n",
    "    return np.minimum(weights, np.quantile(weights, 0.99, method='nearest'))\n",
    "\n",
    "trial_itt.fit_msm(weight_cols=[\"final_weight\"], modify_weights=winsorize_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2.5%'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[411], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m diff_data \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifference\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(diff_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowup_time\u001b[39m\u001b[38;5;124m\"\u001b[39m], diff_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurvival_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvival Difference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(diff_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowup_time\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mdiff_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2.5\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr--\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m95\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m CI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(diff_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowup_time\u001b[39m\u001b[38;5;124m\"\u001b[39m], diff_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97.5\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFollow up\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '2.5%'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trial_itt.predict()\n",
    "diff_data = preds[\"difference\"]\n",
    "plt.plot(diff_data[\"followup_time\"], diff_data[\"survival_diff\"], label=\"Survival Difference\")\n",
    "plt.plot(diff_data[\"followup_time\"], diff_data[\"2.5%\"], \"r--\", label=\"95% CI\")\n",
    "plt.plot(diff_data[\"followup_time\"], diff_data[\"97.5%\"], \"r--\")\n",
    "plt.xlabel(\"Follow up\")\n",
    "plt.ylabel(\"Survival difference\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
