{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 for Clustering: Target Trial Emulation\n",
    "- New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "- In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "1. Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "2. Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "2. Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "3. Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "4. Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "5. Do this by pair, preferably your thesis partner.\n",
    "6. Push to your github repository.\n",
    "7. Deadline is: February 28, 2025 at 11:59 pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import patsy\n",
    "import joblib\n",
    "import json\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import logit\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Class Definition and Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_glm_logit(save_path):\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    def fit_model(numerator, denominator, data):\n",
    "        formula = numerator\n",
    "        try:\n",
    "            model = smf.logit(formula, data).fit(disp=0)  # Suppress convergence messages\n",
    "        except (np.linalg.LinAlgError, sm.tools.sm_exceptions.PerfectSeparationError):\n",
    "            print(f\"Warning: Perfect separation or singular matrix detected for {formula}. Falling back to intercept-only model.\")\n",
    "            formula = f\"{formula.split('~')[0].strip()} ~ 1\"\n",
    "            model = smf.logit(formula, data).fit(disp=0)\n",
    "        model_path = os.path.join(save_path, \"logit_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "        model_details = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_type\": \"te_stats_glm_logit\",\n",
    "            \"file_path\": model_path\n",
    "        }\n",
    "        json.dump(model_details, open(os.path.join(save_path, \"model_details.json\"), \"w\"))\n",
    "        return model\n",
    "    \n",
    "    return fit_model\n",
    "\n",
    "@dataclass\n",
    "class TEDatastore:\n",
    "    data: pd.DataFrame = None\n",
    "\n",
    "    def save_expanded_data(self, switch_data: pd.DataFrame):\n",
    "        if self.data is None:\n",
    "            self.data = switch_data\n",
    "        else:\n",
    "            self.data = pd.concat([self.data, switch_data], ignore_index=True)\n",
    "        return self\n",
    "\n",
    "@dataclass\n",
    "class TEExpansion:\n",
    "    chunk_size: int = 0\n",
    "    datastore: TEDatastore = None\n",
    "    first_period: int = 0\n",
    "    last_period: float = float('inf')\n",
    "    censor_at_switch: bool = False\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand, **kwargs):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = None\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "        self.outcome_data = None\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        self.data[\"followup_time\"] = self.data.groupby(\"id\")[\"period\"].transform(\n",
    "            lambda x: x[(self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)].min()\n",
    "            if ((self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)).any()\n",
    "            else x.max()\n",
    "        )\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"Trial Sequence Object\\nEstimand: {self.estimand}\\n\")\n",
    "        if self.data is not None:\n",
    "            display(self.data)\n",
    "        else:\n",
    "            print(\"No data set\")\n",
    "        print(\"\\nIPW for informative censoring:\")\n",
    "        print(self.censor_weights if self.censor_weights is not None else \"Not calculated.\")\n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\nIPW for treatment switch censoring:\")\n",
    "            print(self.switch_weights)\n",
    "        print(\"\\nOutcome model:\")\n",
    "        print(self.outcome_model if self.outcome_model is not None else \"Not specified.\")\n",
    "        if self.outcome_data is not None:\n",
    "            print(\"\\nOutcome data:\")\n",
    "            print(self.outcome_data)\n",
    "    \n",
    "\n",
    "#Subclass of Trial Sequence, handles the PP (hehe) estimand\n",
    "class TrialSequencePP(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"PP\", **kwargs)\n",
    " \n",
    "#Subclass of Trial Sequence, handles the ITT estimand\n",
    "class TrialSequenceITT(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"ITT\", **kwargs)\n",
    "\n",
    "#trial_sequence function equivalent used in the article\n",
    "def trial_sequence(estimand, **kwargs):\n",
    "    estimand_classes = {\n",
    "        \"PP\": TrialSequencePP,\n",
    "        \"ITT\": TrialSequenceITT\n",
    "    }\n",
    "\n",
    "    if estimand not in estimand_classes:\n",
    "        raise ValueError(f\"{estimand} is not a valid estimand, choose either PP or ITT\")\n",
    "    \n",
    "    return estimand_classes[estimand](**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "A sequence of target trials analysis starts by specifying which estimand will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_pp = trial_sequence(\"PP\")\n",
    "trial_itt = trial_sequence(\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Dummy Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  \n",
       "0          0         0         1  \n",
       "1          0         0         0  \n",
       "2          0         0         0  \n",
       "3          0         0         0  \n",
       "4          0         0         0  \n",
       "..       ...       ...       ...  \n",
       "720        0         0         0  \n",
       "721        0         0         0  \n",
       "722        0         0         0  \n",
       "723        0         0         0  \n",
       "724        1         0         0  \n",
       "\n",
       "[725 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: PP\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n",
      "Trial Sequence Object\n",
      "Estimand: ITT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Extracted Dummy Data\")\n",
    "display(data_censored)\n",
    "data_censored[\"previous_treatment\"] = data_censored[\"treatment\"].shift(1).fillna(0)\n",
    "#Setting the dataset to the data field\n",
    "trial_pp.set_data(data_censored.copy())  # Create a separate copy\n",
    "trial_itt.set_data(data_censored.copy())  \n",
    "\n",
    "\n",
    "#Displaying the info stored in each class\n",
    "trial_pp.show()\n",
    "\n",
    "trial_itt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Weight Models\n",
    "To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. To estimate these weights, we construct time-to-(censoring) event models. Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring.\n",
    "#### 3.1 Censoring due to treatment switching\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_switch_weight_model(self, numerator=None, denominator=None, model_fitter=None, eligible_wts_0=None, eligible_wts_1=None):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"set_data() before setting switch weight models\")\n",
    "        if self.estimand == \"ITT\":\n",
    "            raise ValueError(\"Switching weights are not supported for intention-to-treat analyses\")\n",
    "        if eligible_wts_0 and eligible_wts_0 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_0: \"eligible_wts_0\"})\n",
    "        if eligible_wts_1 and eligible_wts_1 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_1: \"eligible_wts_1\"})\n",
    "        if numerator is None:\n",
    "            numerator = \"1\"\n",
    "        if denominator is None:\n",
    "            denominator = \"1\"\n",
    "        if \"time_on_regime\" in denominator:\n",
    "            raise ValueError(\"time_on_regime should not be used in denominator.\")\n",
    "        formula_numerator = f\"treatment ~ {numerator}\"\n",
    "        formula_denominator = f\"treatment ~ {denominator}\"\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"model_fitter\": \"te_stats_glm_logit\",\n",
    "        }\n",
    "        if model_fitter is not None:\n",
    "            self.switch_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.switch_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_prob_0\"] = self.switch_weights[\"fitted_model_0_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.data[\"switch_prob_1\"] = self.switch_weights[\"fitted_model_1_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_weight\"] = np.where(self.data[\"previous_treatment\"] == 0, \n",
    "                                                  1 / self.data[\"switch_prob_0\"], \n",
    "                                                  1 / self.data[\"switch_prob_1\"])\n",
    "            self.data[\"switch_weight\"] = self.data[\"switch_weight\"].fillna(1)\n",
    "            print(\"Switch weights computed and stored in self.data\")\n",
    "\n",
    "def show_switch_weights(self):\n",
    "    return self.switch_weights if self.switch_weights else \"Not calculated\"\n",
    "    \n",
    "TrialSequence.set_switch_weight_model = set_switch_weight_model\n",
    "TrialSequence.show_switch_weights = show_switch_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose\n",
    "- This function handles the computations of switching weights where patients may change treatments over time.\n",
    "- This is essential because switching treatment throughout the process of the study introduces bias, thus adjusting these weights for those who switch allows for a more unbiased approach.\n",
    "- These weights are calculated through logistic regression models computing the Inverse Probabiliy Weights (IPW).\n",
    "##### Implementation\n",
    "- In the implementation above, the purpose is more or less captured.\n",
    "- We create two models for numerators and denominators and calculate the treatment probabilities given the covariates.\n",
    "- Using the calculated probabilities, separate models are fitted for patients who were previously treated (*previous_treatment == 1*) against those who were never treated. (*previous_treatment == 1*)\n",
    "- Treatment probabilities are then computed and assigned to *switch_prob_0* and *switch_prob_1* and IPW is calculated.\n",
    "- Lastly, it is important to note that we introduce checks for ITT instances being passed as this estimand ignores switching\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch weights computed and stored in self.data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'numerator': 'treatment ~ age',\n",
       " 'denominator': 'treatment ~ age + x1 + x3',\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd17caacf0>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd17c52850>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd17c52d50>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd17c3f360>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Models\"\n",
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_switch_weight_model(numerator=\"age\", denominator=\"age + x1 + x3\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"switch_models\")))\n",
    "trial_pp.show_switch_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Other informative censoring\n",
    "In case there is other informative censoring occurring in the data, we can create similar models to estimate the IPCW. These can be used with all types of estimand. We need to specifycensor_event which is the column containing the censoring indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_censor_weight_model(self, censor_event, numerator=\"1\", denominator=\"1\", pool_models=\"none\", model_fitter=None):\n",
    "    if model_fitter is None:\n",
    "        model_fitter = stats_glm_logit()\n",
    "    if censor_event not in self.data.columns:\n",
    "        raise ValueError(f\"'{censor_event}' must be a column in the dataset.\")\n",
    "    self.data[\"censored_inv\"] = 1 - self.data[censor_event]\n",
    "    formula_numerator = f\"censored_inv ~ {numerator}\"\n",
    "    formula_denominator = f\"censored_inv ~ {denominator}\"\n",
    "    self.censor_weights = {\n",
    "        \"numerator\": formula_numerator,\n",
    "        \"denominator\": formula_denominator,\n",
    "        \"pool_numerator\": pool_models in [\"numerator\", \"both\"],\n",
    "        \"pool_denominator\": pool_models == \"both\",\n",
    "        \"model_fitter\": \"te_stats_glm_logit\"\n",
    "    }\n",
    "    if self.estimand == \"PP\":\n",
    "        self.censor_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "        self.censor_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "        self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "        self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "    elif self.estimand == \"ITT\":\n",
    "        self.censor_weights[\"fitted_model_numerator\"] = model_fitter(formula_numerator, denominator, self.data)\n",
    "        if not self.censor_weights[\"pool_denominator\"]:\n",
    "            self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "\n",
    "def show_censor_weights(self):\n",
    "    return self.censor_weights if self.censor_weights else \"Not calculated\"\n",
    "\n",
    "\n",
    "TrialSequence.set_censor_weight_model = set_censor_weight_model\n",
    "TrialSequence.show_censor_weights = show_censor_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose\n",
    "- Censoring events occur when a participant drops out of the study or is lost to follow-up before an event actually occurs.\n",
    "- These occurences once again introduce bias especially if certain groups are more prone to being censored.\n",
    "- Similarly, we also need to calculate the IPWs of these events to reduce bias in our analysis.\n",
    "##### Implementation\n",
    "- Similar to the calculations found in function *set_switch_weight_models*, *set_censor_weight_models* to some extent, mimics the process found in the earlier section.\n",
    "- It is important to note that we reverse the censoring indicator because IPW requires us to model the probability of **remaining uncensored** rather than **censored**\n",
    "- This is mainly due to the need to weigh individuals on the basis of their likelihood of remaining in the study.\n",
    "- Furthermore, we no longer need to check whether estimands being used are ITT or PP because censoring events happen in both instances.\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': False,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd17c3f820>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd18d0dc70>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd18d38050>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd18d38490>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"none\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_pp.show_censor_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': True,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd18cf8f50>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd18cf9050>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd17c475c0>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 1]\n",
    "trial_itt.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"numerator\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_itt.show_censor_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate Weights\n",
    "Next we need to fit the individual models and combine them into weights. This is done with calculate_weights()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(self, quiet=False):\n",
    "    use_censor_weights = isinstance(self.censor_weights, dict) and (\n",
    "        \"fitted_model_0_denominator\" in self.censor_weights or \"fitted_model_numerator\" in self.censor_weights\n",
    "    )\n",
    "    if self.estimand == \"PP\":\n",
    "        if not (isinstance(self.switch_weights, dict) and \"fitted_model_0_denominator\" in self.switch_weights):\n",
    "            raise ValueError(\"Switch weight models are not specified. Use set_switch_weight_model()\")\n",
    "        self._calculate_weights_trial_seq(quiet, switch_weights=True, censor_weights=use_censor_weights)\n",
    "    elif self.estimand == \"ITT\":\n",
    "        self._calculate_weights_trial_seq(quiet, switch_weights=False, censor_weights=use_censor_weights)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown estimand: {self.estimand}\")\n",
    "\n",
    "def _calculate_weights_trial_seq(self, quiet, switch_weights, censor_weights):\n",
    "    if switch_weights:\n",
    "        if not quiet:\n",
    "            print(\"Calculating switch weights...\")\n",
    "        switch_model_0 = self.switch_weights[\"fitted_model_0_denominator\"]\n",
    "        switch_model_1 = self.switch_weights[\"fitted_model_1_denominator\"]\n",
    "        mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "        mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "        self.data.loc[mask_0, \"switch_prob\"] = switch_model_0.predict(self.data[mask_0])\n",
    "        self.data.loc[mask_1, \"switch_prob\"] = switch_model_1.predict(self.data[mask_1])\n",
    "        self.data[\"switch_prob\"] = self.data[\"switch_prob\"].fillna(1.0)\n",
    "        self.data[\"switch_weight\"] = 1 / self.data[\"switch_prob\"]\n",
    "    if censor_weights:\n",
    "        if not quiet:\n",
    "            print(\"Calculating censor weights...\")\n",
    "        if self.estimand == \"PP\":\n",
    "            censor_model_0 = self.censor_weights[\"fitted_model_0_denominator\"]\n",
    "            censor_model_1 = self.censor_weights[\"fitted_model_1_denominator\"]\n",
    "            mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "            mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "            self.data.loc[mask_0, \"censor_prob\"] = censor_model_0.predict(self.data[mask_0])\n",
    "            self.data.loc[mask_1, \"censor_prob\"] = censor_model_1.predict(self.data[mask_1])\n",
    "        elif self.estimand == \"ITT\":\n",
    "            censor_model = self.censor_weights[\"fitted_model_numerator\"]\n",
    "            self.data[\"censor_prob\"] = censor_model.predict(self.data)\n",
    "        self.data[\"censor_prob\"] = self.data[\"censor_prob\"].fillna(1.0)\n",
    "        self.data[\"censor_weight\"] = 1 / self.data[\"censor_prob\"]\n",
    "    if switch_weights and censor_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"switch_weight\"] * self.data[\"censor_weight\"]\n",
    "    elif switch_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"switch_weight\"]\n",
    "    elif censor_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"censor_weight\"]\n",
    "    if \"switch_weight\" in self.data.columns:\n",
    "        print(\"\\nWeight Summary for PP:\")\n",
    "        print(self.data[[\"switch_weight\", \"censor_weight\", \"final_weight\"]].describe())\n",
    "    else:\n",
    "        print(\"\\nWeight Summary for ITT:\")\n",
    "        print(self.data[[\"censor_weight\", \"final_weight\"]].describe())\n",
    "\n",
    "def show_weight_models(self):\n",
    "    if self.switch_weights is None and self.censor_weights is None:\n",
    "        print(\"No weight models have been set.\")\n",
    "        return\n",
    "\n",
    "    if self.estimand == \"PP\":\n",
    "        print(\"===== PP Estimand (No Pooling) =====\")\n",
    "        if self.censor_weights is not None:\n",
    "            print(\"\\n## Informative Censoring Weights ##\")\n",
    "            for prev_treatment in [0, 1]:\n",
    "                for key in [\"numerator\", \"denominator\"]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                    if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                        print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.censor_weights[model_key].summary())\n",
    "        \n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\n## Treatment Switch Weights ##\")\n",
    "            for prev_treatment in [0, 1]:\n",
    "                for key in [\"numerator\", \"denominator\"]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                    if model_key in self.switch_weights and self.switch_weights[model_key] is not None:\n",
    "                        print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.switch_weights[model_key].summary())\n",
    "    \n",
    "    elif self.estimand == \"ITT\":\n",
    "        print(\"===== ITT Estimand =====\")\n",
    "        if self.censor_weights is not None:\n",
    "            print(\"\\n## Informative Censoring Weights ##\")\n",
    "            if \"fitted_model_numerator\" in self.censor_weights and self.censor_weights[\"fitted_model_numerator\"] is not None:\n",
    "                print(\"\\n# Numerator Model (Pooled)\")\n",
    "                print(self.censor_weights[\"fitted_model_numerator\"].summary())\n",
    "            for prev_treatment in [0, 1]:\n",
    "                model_key = f\"fitted_model_{prev_treatment}_denominator\"\n",
    "                if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                    print(f\"\\n# Denominator Model (Previous Treatment = {prev_treatment})\")\n",
    "                    print(self.censor_weights[model_key].summary())\n",
    "\n",
    "TrialSequence.calculate_weights = calculate_weights\n",
    "TrialSequence._calculate_weights_trial_seq = _calculate_weights_trial_seq\n",
    "TrialSequence.show_weight_models = show_weight_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose\n",
    "- *calculate_weights* is used to compute the final weights used in the survival analysis as these account for treatment switching and censoring events.\n",
    "- Doing so once again ensures unbiased effect estimates and helps to mitigate instances of **Immortal Time Bias** and **Prevalent Time Bias**\n",
    "- However it is important to note that these processed simply **mitigate** these occurences and do not totally remove them.\n",
    "##### Implementation\n",
    "- We implement this process through the use of two main functions, *calculate_weights* and *_calculate_weights_trial_seq*\n",
    "- The former function relies heavily on the latter where majority of the logic is incorporated.\n",
    "- *_calculate_weights_trial_seq* uses the logistic regression models previously generated to calculate the individual weight values for treatment switching and censoring.\n",
    "- Furthermore, if both switch and censor weights are utilized, final weight is calculated by multiply the two values whereas if only one is utilized, it automatically assigns to the final_weight.\n",
    "- The reason we multiply both values in the instance they both occur, is to ensure that we adjust for both biases simlutaneously, properly accounting for both effects together.\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating switch weights...\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for PP:\n",
      "       switch_weight  censor_weight  final_weight\n",
      "count     725.000000     725.000000    725.000000\n",
      "mean        2.733546       1.090906      3.030777\n",
      "std         1.732471       0.070613      2.072097\n",
      "min         1.246125       1.013764      1.329844\n",
      "25%         1.620576       1.048496      1.739213\n",
      "50%         1.955091       1.068877      2.120418\n",
      "75%         3.258089       1.107154      3.581826\n",
      "max        12.525849       1.614490     13.890368\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for ITT:\n",
      "       censor_weight  final_weight\n",
      "count     725.000000    725.000000\n",
      "mean        1.088628      1.088628\n",
      "std         0.044576      0.044576\n",
      "min         1.019809      1.019809\n",
      "25%         1.060133      1.060133\n",
      "50%         1.080359      1.080359\n",
      "75%         1.107915      1.107915\n",
      "max         1.499109      1.499109\n"
     ]
    }
   ],
   "source": [
    "trial_pp.calculate_weights()\n",
    "trial_itt.calculate_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PP Estimand (No Pooling) =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02782\n",
      "Time:                        12:24:54   Log-Likelihood:                -116.34\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.009874\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.3297      0.185     12.625      0.000       1.968       2.691\n",
      "x2            -0.4692      0.184     -2.547      0.011      -0.830      -0.108\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        12:24:54   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02072\n",
      "Time:                        12:24:54   Log-Likelihood:                -79.752\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06621\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6180      0.222     11.796      0.000       2.183       3.053\n",
      "x2            -0.3903      0.210     -1.859      0.063      -0.802       0.021\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        12:24:54   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n",
      "\n",
      "## Treatment Switch Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.05496\n",
      "Time:                        12:24:54   Log-Likelihood:                -232.41\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.001e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7138      0.487      3.520      0.000       0.760       2.668\n",
      "age           -0.0488      0.010     -4.990      0.000      -0.068      -0.030\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      382\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.07371\n",
      "Time:                        12:24:54   Log-Likelihood:                -227.80\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.609e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6569      0.520      3.185      0.001       0.637       2.676\n",
      "age           -0.0526      0.010     -5.236      0.000      -0.072      -0.033\n",
      "x1             0.6504      0.230      2.825      0.005       0.199       1.102\n",
      "x3            -0.2106      0.228     -0.923      0.356      -0.658       0.237\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                0.009356\n",
      "Time:                        12:24:54   Log-Likelihood:                -223.10\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04009\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4232      0.475      2.995      0.003       0.492       2.355\n",
      "age           -0.0204      0.010     -2.040      0.041      -0.040      -0.001\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      335\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02034\n",
      "Time:                        12:24:54   Log-Likelihood:                -220.62\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02721\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.0572      0.520      2.033      0.042       0.038       2.077\n",
      "age           -0.0180      0.010     -1.762      0.078      -0.038       0.002\n",
      "x1             0.5117      0.257      1.995      0.046       0.009       1.014\n",
      "x3             0.2281      0.230      0.992      0.321      -0.223       0.679\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_pp.show_weight_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ITT Estimand =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Pooled)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        12:24:54   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.4481      0.141     17.415      0.000       2.173       2.724\n",
      "x2            -0.4486      0.137     -3.278      0.001      -0.717      -0.180\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        12:24:54   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        12:24:54   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_itt.show_weight_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Specify Outcome Model\n",
    "Now we can specify the outcome model. Here we can include adjustment terms for any variables in the dataset. The numerator terms from the stabilised weight models are automatically included in the outcome model formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5\n",
    "def set_outcome_model(self, adjustment_terms=None, model_fitter=None):\n",
    "    if self.data is None:\n",
    "        raise ValueError(\"set_data() before defining the outcome model.\")\n",
    "\n",
    "    treatment_var = \"treatment\"\n",
    "\n",
    "    # Extract stabilized weight terms\n",
    "    stabilised_weight_terms = []\n",
    "    if self.switch_weights:\n",
    "        stabilised_weight_terms.append(self.switch_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "    if self.censor_weights:\n",
    "        stabilised_weight_terms.append(self.censor_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "\n",
    "    stabilised_weight_terms = \" + \".join(stabilised_weight_terms) if stabilised_weight_terms else \"1\"\n",
    "\n",
    "    # Default adjustment terms based on estimand\n",
    "    if adjustment_terms is None:\n",
    "        adjustment_terms = [\"x1\", \"x2\", \"x3\", \"age\"] if self.estimand == \"PP\" else [\"x2\"]\n",
    "    elif isinstance(adjustment_terms, str):\n",
    "        adjustment_terms = adjustment_terms.split(\" + \")\n",
    "\n",
    "    # Polynomial terms for time effects\n",
    "    additional_terms = []\n",
    "\n",
    "    if \"period\" in self.data.columns:\n",
    "        additional_terms.extend([\"trial_period\", \"I(trial_period**2)\"])\n",
    "\n",
    "    # Ensure unique terms using a set\n",
    "    all_terms = set([treatment_var] + adjustment_terms + additional_terms)\n",
    "    stabilised_terms = set(stabilised_weight_terms.split(\" + \"))  # Convert to set\n",
    "\n",
    "    # Merge while keeping unique terms\n",
    "    final_terms = all_terms | stabilised_terms\n",
    "    final_terms.discard(\"1\")\n",
    "\n",
    "    formula = \"outcome ~ \" + \" + \".join(sorted(final_terms))  # Sort for consistency\n",
    "\n",
    "    # Ensure weights exist\n",
    "    if \"final_weight\" not in self.data.columns:\n",
    "        raise ValueError(\"Weights have not been calculated. Run calculate_weights() first.\")\n",
    "\n",
    "    # Default to logistic regression model fitter if none is provided\n",
    "    if model_fitter is None:\n",
    "        model_fitter = stats_glm_logit(save_path=None)\n",
    "\n",
    "    # Store in outcome_model dictionary\n",
    "    self.outcome_model = {\n",
    "        \"formula\": formula,\n",
    "        \"treatment_var\": treatment_var,\n",
    "        \"adjustment_vars\": list(all_terms), \n",
    "        \"stabilised_weights_terms\": \" + \".join(sorted(stabilised_terms)), \n",
    "        \"model_fitter\": model_fitter,\n",
    "        \"fitted\": None \n",
    "    }\n",
    "\n",
    "    return self\n",
    "\n",
    "def show_outcome_model(self):\n",
    "    return self.outcome_model if self.outcome_model else \"Not calculated\"\n",
    "\n",
    "TrialSequence.set_outcome_model = set_outcome_model\n",
    "TrialSequence.show_outcome_model = show_outcome_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose\n",
    "- Typically, TTE outcome models model hazard or survival probability over time and handles right-censoring explicitly.\n",
    "- However, in our implementation above we are actually using a formula-based regression model which is not a typical TTE model.\n",
    "- The reason for this mainly comes from a misunderstanding of the R code documentation we utilized as basis for the conversion of this code.\n",
    "##### Implementation\n",
    "- Our implementation follows a marginal structural model approach as it uses weighted regression instead of the actualy survival modeling typically used in TTEs\n",
    "- As a result, our implementation does not explicitly model time-to-event but instead adjusts for time-dependent confounding using stabilized weights calculated in previous steps.\n",
    "- This then leads to the estimation of effects of treatment on an outcome rather than modeling the time until an event.\n",
    "\n",
    "##### Food For Thought 🤔 (Since no more time to revise implementation)\n",
    "- Does the R code we used as reference really introduce Cox regression instead of Inverse Proability Weighting?\n",
    "- If it uses IPW, does that mean the actual R documentation is wrong in its TTE implementation? \n",
    "- Or our understanding of the process might just be wrong overall \n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': 'outcome ~ I(trial_period**2) + age + treatment + trial_period + x1 + x2 + x3',\n",
       " 'treatment_var': 'treatment',\n",
       " 'adjustment_vars': ['trial_period',\n",
       "  'x2',\n",
       "  'age',\n",
       "  'x3',\n",
       "  'treatment',\n",
       "  'x1',\n",
       "  'I(trial_period**2)'],\n",
       " 'stabilised_weights_terms': 'age + x2',\n",
       " 'model_fitter': <function __main__.stats_glm_logit.<locals>.fit_model(numerator, denominator, data)>,\n",
       " 'fitted': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_pp.set_outcome_model()  \n",
    "trial_itt.set_outcome_model(adjustment_terms=\"x2\")  \n",
    "trial_pp.show_outcome_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expand Trials\n",
    "Now we are ready to create the data set with all of the sequence of target trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_expansion_options(self, output: TEDatastore, chunk_size: int = 0, first_period: int = 0, last_period: float = float('inf'), censor_at_switch: bool = False):\n",
    "    \n",
    "    self.expansion = TEExpansion(chunk_size = chunk_size, datastore = output, first_period = first_period, last_period = last_period, censor_at_switch = censor_at_switch)\n",
    "\n",
    "    return self\n",
    "\n",
    "TrialSequence.set_expansion_options = set_expansion_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x1fd17ca8980>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = TEDatastore()\n",
    "trial_pp.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = True)\n",
    "trial_itt.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Create Sequence of Trials Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_trials(self):\n",
    "    data = self.data.copy()\n",
    "    outcome_adj_vars = self.get_outcome_adjustment_vars()\n",
    "    keeplist = list(set(['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2', 'age'] + outcome_adj_vars))\n",
    "\n",
    "    if 'wt' not in data.columns:\n",
    "        data['wt'] = 1\n",
    "\n",
    "    all_ids = data['id'].unique()\n",
    "    if self.expansion.chunk_size == 0:\n",
    "        ids_split = [all_ids]\n",
    "    else:\n",
    "        ids_split = np.array_split(all_ids, np.ceil(len(all_ids) / self.expansion.chunk_size))\n",
    "\n",
    "    for ids in ids_split:\n",
    "        switch_data = self._expand_chunk(data, ids, outcome_adj_vars, keeplist)\n",
    "        self.expansion.datastore = self.expansion.datastore.save_expanded_data(switch_data)\n",
    "\n",
    "    return self\n",
    "\n",
    "def _expand_chunk(self, data: pd.DataFrame, ids: np.ndarray, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "    chunk_data = data[data['id'].isin(ids)].copy()\n",
    "\n",
    "    first_period = max([self.expansion.first_period, chunk_data[chunk_data['eligible'] == 1]['period'].min() or self.expansion.first_period])\n",
    "    last_period = min([self.expansion.last_period, chunk_data[chunk_data['eligible'] == 1]['period'].max() or self.expansion.last_period])\n",
    "    \n",
    "    expanded_data = []\n",
    "    for _, row in chunk_data.iterrows():\n",
    "        if row['eligible'] == 1 and first_period <= row['period'] <= last_period:\n",
    "            trial_start = row['period']\n",
    "            trial_data = self._generate_trial_instance(row, chunk_data, trial_start, last_period, outcome_adj_vars, keeplist)\n",
    "            expanded_data.append(trial_data)\n",
    "\n",
    "    result = pd.concat(expanded_data, ignore_index=True) if expanded_data else pd.DataFrame()\n",
    "\n",
    "    return result[keeplist]\n",
    "\n",
    "def _generate_trial_instance(self, baseline_row: pd.Series, data: pd.DataFrame, trial_start: int, last_period: float, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "\n",
    "    id_val = baseline_row['id']\n",
    "    patient_data = data[data['id'] == id_val].sort_values('period')\n",
    "    rows = []\n",
    "\n",
    "    if pd.isna(last_period) or last_period == float('inf'):\n",
    "        last_period_value = patient_data['period'].max()\n",
    "    else:\n",
    "        last_period_value = last_period\n",
    "\n",
    "    # Convert float to integer to handle errors\n",
    "    if pd.notna(last_period_value):\n",
    "        last_period_int = int(np.floor(float(last_period_value)))\n",
    "    else:\n",
    "        last_period_int = int(trial_start)\n",
    "\n",
    "    max_period_value = patient_data['period'].max()\n",
    "    if pd.notna(max_period_value):\n",
    "        max_period = int(np.floor(float(max_period_value)))\n",
    "    else:\n",
    "        max_period = last_period_int \n",
    "\n",
    "    last_period_int = int(last_period_int)\n",
    "    max_period = int(max_period)\n",
    "\n",
    "    for period in range(int(trial_start), int(min(last_period_int + 1, max_period + 1))):\n",
    "        period_row = patient_data[patient_data['period'] == period].iloc[0] if not patient_data[patient_data['period'] == period].empty else None\n",
    "        \n",
    "        if period_row is None:\n",
    "            continue\n",
    "\n",
    "        if self.expansion.censor_at_switch and period > trial_start:\n",
    "            prev_row = patient_data[patient_data['period'] == (period - 1)].iloc[0]\n",
    "            if prev_row['treatment'] != period_row['treatment']:\n",
    "                break  # Censor at switch\n",
    "\n",
    "        trial_period = period - trial_start\n",
    "        followup_time = period - trial_start\n",
    "        final_weight = self.data[(self.data['id'] == id_val) & (self.data['period'] == period)]['final_weight'].iloc[0] if not self.data[(self.data['id'] == id_val) & (self.data['period'] == period)].empty else 1.0\n",
    "        row_dict = {\n",
    "            'id': id_val,\n",
    "            'trial_period': trial_period,\n",
    "            'followup_time': followup_time,\n",
    "            'outcome': period_row['outcome'],\n",
    "            'weight': final_weight,  \n",
    "            'treatment': period_row['treatment'],\n",
    "        }\n",
    "        \n",
    "        for var in outcome_adj_vars + ['age', 'x2']:\n",
    "            if var in patient_data.columns:\n",
    "                row_dict[var] = period_row.get(var, np.nan)\n",
    "            else:\n",
    "                row_dict[var] = np.nan \n",
    "\n",
    "        rows.append(pd.Series(row_dict))\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    int_columns = ['id', 'trial_period', 'followup_time', 'outcome', 'treatment', 'age']\n",
    "    df[int_columns] = df[int_columns].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_outcome_adjustment_vars(self):\n",
    "    return getattr(self.outcome_model, 'adjustment_vars', [])\n",
    "\n",
    "\n",
    "TrialSequence.expand_trials = expand_trials\n",
    "TrialSequence._expand_chunk = _expand_chunk\n",
    "TrialSequence._generate_trial_instance = _generate_trial_instance\n",
    "TrialSequence.get_outcome_adjustment_vars = get_outcome_adjustment_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose \n",
    "- Expanding Trials restructures the dataset in a way to allow for time-varying analysis\n",
    "- This is done to replicate a Randomized Control Trial (RCT) by turning the observational data taken from *data_censored* into one that would typically be collected in an actual trial.\n",
    "- From our understanding, each patient's data is typically duplicated at every point of eligibility until an event occurs.\n",
    "##### Implementation\n",
    "- As a result, we generate multiple rows for every Patient ID, which each represents a time period within the study.\n",
    "- We incorporate treatment switching handling, wherein if a patients treatment variable changes, the observation stops. This prevents contamination of treatment effects due to switching.\n",
    "- Time-dependent covariates are taken into account such as age and x2 as they can be modeled as time-varying instead of static.\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanded Data:\n"
     ]
    }
   ],
   "source": [
    "trial_pp.expand_trials()\n",
    "trial_itt.expand_trials()\n",
    "print(\"\\nExpanded Data:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load or Sample Expanded Data\n",
    "Now that the expanded data has been created, we can prepare the data to fit the outcome model. For data that can fit comfortably in memory, this is a trivial step using load_expanded_data.\n",
    "\n",
    "For large datasets, it may be necessary to sample from the expanded by setting the p_control argument. This sets the probability that an observation with outcome == 0 will be included in the loaded data. A seed can be set for reproducibility. Additionally, a vector of periods to include can be specified, e.g., period = 1:60, and/or a subsetting condition, subset_condition = \"age > 65\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expanded_data(self, p_control: Optional[float] = None, period: Optional[List[int]] = None, subset_condition: Optional[str] = None, seed: Optional[int] = None):\n",
    "    \n",
    "    if p_control is None:\n",
    "        data_table = self.expansion.datastore.data.copy()\n",
    "        data_table['sample_weight'] = 1\n",
    "    else:\n",
    "        np.random.seed(seed) if seed is not None else np.random.seed()\n",
    "        data_table = self.expansion.datastore.data.copy()\n",
    "\n",
    "        mask_outcome_1 = data_table['outcome'] == 1\n",
    "        mask_outcome_0 = data_table['outcome'] == 0\n",
    "        sampled_0 = data_table[mask_outcome_0].sample(frac=p_control, replace=False)\n",
    "        data_table = pd.concat([data_table[mask_outcome_1], sampled_0])\n",
    "\n",
    "        data_table.loc[mask_outcome_0, 'sample_weight'] = 1 / p_control if p_control > 0 else 1\n",
    "        data_table.loc[mask_outcome_1, 'sample_weight'] = 1\n",
    "\n",
    "    if period is not None:\n",
    "        data_table = data_table[data_table['trial_period'].isin(period) | data_table['followup_time'].isin(period)]\n",
    "    \n",
    "    if subset_condition is not None:\n",
    "        data_table = data_table.query(subset_condition)\n",
    "    \n",
    "    data_table = data_table.sort_values(['id', 'trial_period', 'followup_time'])\n",
    "    data_table = data_table.reset_index(drop=True)\n",
    "    \n",
    "    self.outcome_data = data_table\n",
    "    \n",
    "    return self\n",
    "\n",
    "TrialSequence.load_expanded_data = load_expanded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose\n",
    "- The main goal of loading expanded data, is to filter out the expanded trial data generated in **Step 6**. \n",
    "- Performing sampling and subsetting is done to adjust for imbalances found in the dataset\n",
    "- This helps prepare the dataset for causal inference analysis, ensuring that the data in *outcome_model* reflects the appropriate structure.\n",
    "##### Implementation\n",
    "- Given a *p_control* value, we randomly down-sample the observations where *outcome == 0*, which essentially only keeps a fraction of them as declared by the *p_control* value.\n",
    "- This ensures that imbalanced outcomes are formatted into a more manageable dataset size. \n",
    "- Moreover, we assign weight adjustments to sample instances so that missing observations are still accounted for.\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x1fd17ca8980>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_pp.load_expanded_data(p_control = 0.5, seed=1234)\n",
    "trial_itt.load_expanded_data(p_control = 0.5, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fit Marginal Structural Model\n",
    "To fit the outcome model we use fit_msm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_msm(self, weight_cols=[\"weight\"], modify_weights=None, family=\"binomial\"):\n",
    "    if not self.outcome_model:\n",
    "        raise ValueError(\"Outcome model not defined. Run set_outcome_model() first.\")\n",
    "    \n",
    "    formula = self.outcome_model[\"formula\"]\n",
    "    print(f\"Using formula from set_outcome_model: {formula}\")\n",
    "    \n",
    "    weight_col = next(col for col in weight_cols if col in self.outcome_data.columns)\n",
    "    data = self.outcome_data[~self.outcome_data[weight_col].isna()].copy()\n",
    "    weights = data[weight_col].values\n",
    "    \n",
    "    if modify_weights:\n",
    "        weights = modify_weights(weights)\n",
    "    \n",
    "    # Fit the MSM\n",
    "    try:\n",
    "        if family == \"binomial\":\n",
    "            model = smf.logit(formula, data=data)\n",
    "            fitted_model = model.fit(method='lbfgs', weights=weights, disp=0, maxiter=100)\n",
    "        elif family == \"gaussian\":\n",
    "            model = smf.ols(formula, data=data, weights=weights)\n",
    "            fitted_model = model.fit()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported family. Use 'binomial' or 'gaussian'.\")\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        raise ValueError(f\"Model fitting failed due to singular matrix: {e}.\")\n",
    "    \n",
    "    print(\"MSM Fit Summary:\")\n",
    "    print(fitted_model.summary())\n",
    "    self.outcome_model[\"fitted\"] = fitted_model\n",
    "    return fitted_model\n",
    "\n",
    "TrialSequence.fit_msm = fit_msm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose\n",
    "- The main purpose of this section is as the title suggests, we fit a Marginal Structural Model using the formulas generated from the **outcome_model** while applying the IPWs generated. \n",
    "- Doing this enables us to estimate the causal effects of treatment on the outcome by adjusting for time-varying confounders over time.\n",
    "- Implementing this method allows us to generate a causal interpretation of treatment effects in **longitudal studies**\n",
    "##### Implementation\n",
    "- We extract the previously defined formulas which specify what variables will be used in the regression model.\n",
    "- We filter the weight columns to remove missing values to ensure that this value exists for all observations.\n",
    "- These weights are then used for the weighted regression.\n",
    "- Finally, based on what **\"family\"** is passed in, the regression model is selected. *binomial for logistic regression* and *gaussian for linear regression*\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using formula from set_outcome_model: outcome ~ I(trial_period**2) + treatment + trial_period + x2\n",
      "MSM Fit Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  970\n",
      "Model:                          Logit   Df Residuals:                      965\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sun, 09 Mar 2025   Pseudo R-squ.:                 0.01472\n",
      "Time:                        12:24:58   Log-Likelihood:                -80.342\n",
      "converged:                       True   LL-Null:                       -81.543\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6625\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -4.4163      0.570     -7.746      0.000      -5.534      -3.299\n",
      "I(trial_period ** 2)    -0.0086      0.012     -0.720      0.472      -0.032       0.015\n",
      "treatment               -0.3057      0.545     -0.560      0.575      -1.375       0.763\n",
      "trial_period             0.1617      0.180      0.897      0.370      -0.192       0.515\n",
      "x2                       0.2741      0.259      1.059      0.290      -0.233       0.782\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1fd1ce7f6b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def winsorize_weights(weights):\n",
    "    #99th percentile values\n",
    "    return np.minimum(weights, np.quantile(weights, 0.99, method='nearest'))\n",
    "\n",
    "trial_itt.fit_msm(weight_cols=[\"weight\"], modify_weights=winsorize_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Inference\n",
    "We use the predict() method to estimate survival probabilities or cumulative incidences for different values of assigned_treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, newdata=None, predict_times=None, type=\"survival\"):\n",
    "    \n",
    "    if newdata is None:\n",
    "        if self.outcome_data is None:\n",
    "            raise ValueError(\"outcome_data not available. Run load_expanded_data() first.\")\n",
    "        data = self.outcome_data.copy()\n",
    "    else:\n",
    "        data = newdata.copy()\n",
    "    \n",
    "    if predict_times is None:\n",
    "        predict_times = np.arange(0, 21)\n",
    "    \n",
    "    predict_times = np.array(predict_times, dtype=int)\n",
    "    \n",
    "    model = self.outcome_model[\"fitted\"]\n",
    "    \n",
    "    data_control = data.copy()\n",
    "    data_control[\"treatment\"] = 0  # Control group\n",
    "    \n",
    "    data_treated = data.copy()\n",
    "    data_treated[\"treatment\"] = 1  # Treated group\n",
    "    \n",
    "    # Predict probabilities for all data, then filter by predict_times\n",
    "    preds_control = model.predict(data_control)\n",
    "    preds_treated = model.predict(data_treated)\n",
    "    \n",
    "    survival_control = 1 - pd.Series(preds_control).groupby(data_control[\"followup_time\"]).mean()\n",
    "    survival_treated = 1 - pd.Series(preds_treated).groupby(data_treated[\"followup_time\"]).mean()\n",
    "    \n",
    "    survival_diff = (survival_treated.reindex(predict_times).ffill().fillna(0) - survival_control.reindex(predict_times).ffill().fillna(0))\n",
    "    \n",
    "    ci_lower = survival_diff - 1.96 * np.std(survival_diff)\n",
    "    ci_upper = survival_diff + 1.96 * np.std(survival_diff)\n",
    "    \n",
    "    # Step graph was ugly so we let gpt generate a smoother curve AHAHAHA\n",
    "    fine_times = np.linspace(predict_times.min(), predict_times.max(), 100)\n",
    "    \n",
    "    interp_diff = interp1d(predict_times, survival_diff, kind='cubic', fill_value=\"extrapolate\")\n",
    "    interp_lower = interp1d(predict_times, ci_lower, kind='cubic', fill_value=\"extrapolate\")\n",
    "    interp_upper = interp1d(predict_times, ci_upper, kind='cubic', fill_value=\"extrapolate\")\n",
    "    \n",
    "    smooth_diff = interp_diff(fine_times)\n",
    "    smooth_lower = interp_lower(fine_times)\n",
    "    smooth_upper = interp_upper(fine_times)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(fine_times, smooth_diff, label=\"Survival Difference\", color=\"blue\")\n",
    "    plt.plot(fine_times, smooth_lower, linestyle='--', color=\"red\", label=\"95% CI Lower Bound\")\n",
    "    plt.plot(fine_times, smooth_upper, linestyle='--', color=\"red\", label=\"95% CI Upper Bound\")\n",
    "    \n",
    "    plt.xlabel(\"Follow-up Time\")\n",
    "    plt.ylabel(\"Survival Difference\")\n",
    "    plt.title(\"Predicted Survival Difference Over Time\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "TrialSequence.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purpose \n",
    "- This function is estimating the survival difference between the treated and control groups over time.\n",
    "- We utilize the predictions taken from the fitted Marginal Structure Model and use it to predict survival probabilities and the survival difference.\n",
    "- Essentially, this function is used to show how treatment affects survival at different time points and helps us understand the stability of treatment effects over time.\n",
    "##### Implementation\n",
    "- We first define the time points at which survival differences will be predicted.\n",
    "- We then extract the fitted MSM model and create two data sets keeping track of the treated and untreated patients. Doing so allows for a counterfactual comparison\n",
    "- Predicting the outcome under both scenarios then follows along with the survival differences among the two groups.\n",
    "- Assuming normal approximation, the confidence intervals are calculated to provide us with an interval within which we expect the true survival difference to fall with 95% confidence.\n",
    "- The rest of the lines of code are for fine-tuning the graph.\n",
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial_itt.predict(type=\"difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Insights\n",
    "Based on the graph, a dynamic pattern can be identified wherein we see an initial rise then followed by a steady decline with a 95% confidence interval lower and upper bounds tracking this trend\n",
    "### Graph Trend\n",
    "1. The survival difference starts at around 0.003 at time follow-up time 0 and rises steadily to peak at around 0.006 ~ 0.007 between the time intervals of 7.5 - 10.\n",
    "2. What we can infer from this is that the treatment provides an early beneficial effect, with the difference in survival probabilities growing over the initial follow-up period.\n",
    "3. After the hitting the peak, the survival difference declines hitting a low of 0.003 - 0.004, only slightly higher than the initial difference at follow-up time 0.\n",
    "4. This indicates that the treatment benefit diminishes after a certain point, due to underlying factors not indicated in this current implementation. \n",
    "5. However, one could conclude these underlying factors may be due to treatment resistance, adverse effects, or hitting a ceiling effect in survival improvement.\n",
    "6. After hitting the low, it seems to remain steady at around the 0.003 - 0.004 difference area, indicating that starting at a follow-up time of around 17.5, the medicinal effects provide only very minute beneficial effects.\n",
    "\n",
    "### Confidence Interval\n",
    "1. The CI bounds widen slightly as the survival difference increases, reflecting greater uncertainty at the peak. Post-peak, the CI narrows but still remains relatively wide, indicating variability in the estimate as the difference declines.\n",
    "2. The CI includes zero early on, but the lower bound rises above zero and stays positive at around 2.5 - 5 follow-up time. This suggests statistical significance after this initial period. \n",
    "3. Further, the decline phase still keeps the CI above zero, indicating the treatment effects still remain significant even as it weakens. \n",
    "4. It is important to note that because of the symmetric CI based on ±1.96 * std, overestimation or underestimation may be truly uncertain, especially given the dynamic trend. \n",
    "\n",
    "### Potential Clinical or Research Implications\n",
    "1. The peak at followup-time 5 - 7.5 suggets an optimal period for observing the treatments maximum benefits. Clinical intervetnsions may focus on this particular time period to maximize efficiency.\n",
    "2. The decline after the peak opens up avenues to look into the long-term side effects, resistance, or the need for alternative therapies after this period. \n",
    "3. Perhaps adjustments in dosage, combination of therapies, or patient selection might be warranted to maintain benefits beyond the peak. \n",
    "\n",
    "### Why might our results be different from the R article?\n",
    "1. This could come from varying areas across our implementation. However, it is evident that the our implementation starts to incorporate different implementions from Step 5 onward. \n",
    "2. These varying implementations could have led to the difference in results, wherein our generated graph follows a more parabolic shape whereas in the provided article, the graph is a steady decline.\n",
    "3. One thing to note is that typical Target-Trial-Emulations utilize Cox Regression models, whereas we utilized a Weighted Regression Model, both of which measure different things. \n",
    "4. Cox's Regression Model measures the hazard ratio or essentially the instantaneous risk over time whereas the Weighted Regression Model used here, measures the population-level treatment effects. \n",
    "5. The latter was user in our **Step 5** implementation, which could have been one of the main contributors to this variation in generated data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
