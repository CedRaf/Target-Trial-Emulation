{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 for Clustering: Target Trial Emulation\n",
    "- New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "- In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "1. Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "2. Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "2. Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "3. Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "4. Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "5. Do this by pair, preferably your thesis partner.\n",
    "6. Push to your github repository.\n",
    "7. Deadline is: February 28, 2025 at 11:59 pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import patsy\n",
    "import joblib\n",
    "import json\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import logit\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Class Definition and Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_glm_logit(save_path):\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    def fit_model(numerator, denominator, data):\n",
    "        formula = numerator\n",
    "        try:\n",
    "            model = smf.logit(formula, data).fit(disp=0)  # Suppress convergence messages\n",
    "        except (np.linalg.LinAlgError, sm.tools.sm_exceptions.PerfectSeparationError):\n",
    "            print(f\"Warning: Perfect separation or singular matrix detected for {formula}. Falling back to intercept-only model.\")\n",
    "            formula = f\"{formula.split('~')[0].strip()} ~ 1\"\n",
    "            model = smf.logit(formula, data).fit(disp=0)\n",
    "        model_path = os.path.join(save_path, \"logit_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "        model_details = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_type\": \"te_stats_glm_logit\",\n",
    "            \"file_path\": model_path\n",
    "        }\n",
    "        json.dump(model_details, open(os.path.join(save_path, \"model_details.json\"), \"w\"))\n",
    "        return model\n",
    "    \n",
    "    return fit_model\n",
    "\n",
    "@dataclass\n",
    "class TEDatastore:\n",
    "    data: pd.DataFrame = None\n",
    "\n",
    "    def save_expanded_data(self, switch_data: pd.DataFrame):\n",
    "        if self.data is None:\n",
    "            self.data = switch_data\n",
    "        else:\n",
    "            self.data = pd.concat([self.data, switch_data], ignore_index=True)\n",
    "        return self\n",
    "\n",
    "@dataclass\n",
    "class TEExpansion:\n",
    "    chunk_size: int = 0\n",
    "    datastore: TEDatastore = None\n",
    "    first_period: int = 0\n",
    "    last_period: float = float('inf')\n",
    "    censor_at_switch: bool = False\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand, **kwargs):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = None\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "        self.outcome_data = None\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        self.data[\"followup_time\"] = self.data.groupby(\"id\")[\"period\"].transform(\n",
    "            lambda x: x[(self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)].min()\n",
    "            if ((self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)).any()\n",
    "            else x.max()\n",
    "        )\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"Trial Sequence Object\\nEstimand: {self.estimand}\\n\")\n",
    "        if self.data is not None:\n",
    "            display(self.data)\n",
    "        else:\n",
    "            print(\"No data set\")\n",
    "        print(\"\\nIPW for informative censoring:\")\n",
    "        print(self.censor_weights if self.censor_weights is not None else \"Not calculated.\")\n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\nIPW for treatment switch censoring:\")\n",
    "            print(self.switch_weights)\n",
    "        print(\"\\nOutcome model:\")\n",
    "        print(self.outcome_model if self.outcome_model is not None else \"Not specified.\")\n",
    "        if self.outcome_data is not None:\n",
    "            print(\"\\nOutcome data:\")\n",
    "            print(self.outcome_data)\n",
    "    \n",
    "\n",
    "#Subclass of Trial Sequence, handles the PP (hehe) estimand\n",
    "class TrialSequencePP(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"PP\", **kwargs)\n",
    " \n",
    "#Subclass of Trial Sequence, handles the ITT estimand\n",
    "class TrialSequenceITT(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"ITT\", **kwargs)\n",
    "\n",
    "#trial_sequence function equivalent used in the article\n",
    "def trial_sequence(estimand, **kwargs):\n",
    "    estimand_classes = {\n",
    "        \"PP\": TrialSequencePP,\n",
    "        \"ITT\": TrialSequenceITT\n",
    "    }\n",
    "\n",
    "    if estimand not in estimand_classes:\n",
    "        raise ValueError(f\"{estimand} is not a valid estimand, choose either PP or ITT\")\n",
    "    \n",
    "    return estimand_classes[estimand](**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "A sequence of target trials analysis starts by specifying which estimand will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_pp = trial_sequence(\"PP\")\n",
    "trial_itt = trial_sequence(\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Dummy Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  \n",
       "0          0         0         1  \n",
       "1          0         0         0  \n",
       "2          0         0         0  \n",
       "3          0         0         0  \n",
       "4          0         0         0  \n",
       "..       ...       ...       ...  \n",
       "720        0         0         0  \n",
       "721        0         0         0  \n",
       "722        0         0         0  \n",
       "723        0         0         0  \n",
       "724        1         0         0  \n",
       "\n",
       "[725 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: PP\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n",
      "Trial Sequence Object\n",
      "Estimand: ITT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Extracted Dummy Data\")\n",
    "display(data_censored)\n",
    "data_censored[\"previous_treatment\"] = data_censored[\"treatment\"].shift(1).fillna(0)\n",
    "#Setting the dataset to the data field\n",
    "trial_pp.set_data(data_censored.copy())  # Create a separate copy\n",
    "trial_itt.set_data(data_censored.copy())  \n",
    "\n",
    "\n",
    "#Displaying the info stored in each class\n",
    "trial_pp.show()\n",
    "\n",
    "trial_itt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Weight Models\n",
    "To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. To estimate these weights, we construct time-to-(censoring) event models. Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring.\n",
    "#### 3.1 Censoring due to treatment switching\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_switch_weight_model(self, numerator=None, denominator=None, model_fitter=None, eligible_wts_0=None, eligible_wts_1=None):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"set_data() before setting switch weight models\")\n",
    "        if self.estimand == \"ITT\":\n",
    "            raise ValueError(\"Switching weights are not supported for intention-to-treat analyses\")\n",
    "        if eligible_wts_0 and eligible_wts_0 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_0: \"eligible_wts_0\"})\n",
    "        if eligible_wts_1 and eligible_wts_1 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_1: \"eligible_wts_1\"})\n",
    "        if numerator is None:\n",
    "            numerator = \"1\"\n",
    "        if denominator is None:\n",
    "            denominator = \"1\"\n",
    "        if \"time_on_regime\" in denominator:\n",
    "            raise ValueError(\"time_on_regime should not be used in denominator.\")\n",
    "        formula_numerator = f\"treatment ~ {numerator}\"\n",
    "        formula_denominator = f\"treatment ~ {denominator}\"\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"model_fitter\": \"te_stats_glm_logit\",\n",
    "        }\n",
    "        if model_fitter is not None:\n",
    "            self.switch_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.switch_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_prob_0\"] = self.switch_weights[\"fitted_model_0_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.data[\"switch_prob_1\"] = self.switch_weights[\"fitted_model_1_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_weight\"] = np.where(self.data[\"previous_treatment\"] == 0, \n",
    "                                                  1 / self.data[\"switch_prob_0\"], \n",
    "                                                  1 / self.data[\"switch_prob_1\"])\n",
    "            self.data[\"switch_weight\"] = self.data[\"switch_weight\"].fillna(1)\n",
    "            print(\"Switch weights computed and stored in self.data\")\n",
    "\n",
    "def show_switch_weights(self):\n",
    "    return self.switch_weights if self.switch_weights else \"Not calculated\"\n",
    "    \n",
    "TrialSequence.set_switch_weight_model = set_switch_weight_model\n",
    "TrialSequence.show_switch_weights = show_switch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch weights computed and stored in self.data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'numerator': 'treatment ~ age',\n",
       " 'denominator': 'treatment ~ age + x1 + x3',\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973eb8a6f0>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f37f0b0>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f1e77d0>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f330a10>}"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Models\"\n",
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_switch_weight_model(numerator=\"age\", denominator=\"age + x1 + x3\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"switch_models\")))\n",
    "trial_pp.show_switch_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Other informative censoring\n",
    "In case there is other informative censoring occurring in the data, we can create similar models to estimate the IPCW. These can be used with all types of estimand. We need to specifycensor_event which is the column containing the censoring indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_censor_weight_model(self, censor_event, numerator=\"1\", denominator=\"1\", pool_models=\"none\", model_fitter=None):\n",
    "    if model_fitter is None:\n",
    "        model_fitter = stats_glm_logit()\n",
    "    if censor_event not in self.data.columns:\n",
    "        raise ValueError(f\"'{censor_event}' must be a column in the dataset.\")\n",
    "    self.data[\"censored_inv\"] = 1 - self.data[censor_event]\n",
    "    formula_numerator = f\"censored_inv ~ {numerator}\"\n",
    "    formula_denominator = f\"censored_inv ~ {denominator}\"\n",
    "    self.censor_weights = {\n",
    "        \"numerator\": formula_numerator,\n",
    "        \"denominator\": formula_denominator,\n",
    "        \"pool_numerator\": pool_models in [\"numerator\", \"both\"],\n",
    "        \"pool_denominator\": pool_models == \"both\",\n",
    "        \"model_fitter\": \"te_stats_glm_logit\"\n",
    "    }\n",
    "    if self.estimand == \"PP\":\n",
    "        self.censor_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "        self.censor_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "        self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "        self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "    elif self.estimand == \"ITT\":\n",
    "        self.censor_weights[\"fitted_model_numerator\"] = model_fitter(formula_numerator, denominator, self.data)\n",
    "        if not self.censor_weights[\"pool_denominator\"]:\n",
    "            self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "\n",
    "def show_censor_weights(self):\n",
    "    return self.censor_weights if self.censor_weights else \"Not calculated\"\n",
    "\n",
    "\n",
    "TrialSequence.set_censor_weight_model = set_censor_weight_model\n",
    "TrialSequence.show_censor_weights = show_censor_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': False,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f104470>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f40e690>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f40eed0>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f40d070>}"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"none\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_pp.show_censor_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': True,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d32fb30>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f330710>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f3b8cb0>}"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 1]\n",
    "trial_itt.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"numerator\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_itt.show_censor_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate Weights\n",
    "Next we need to fit the individual models and combine them into weights. This is done with calculate_weights()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(self, quiet=False):\n",
    "    use_censor_weights = isinstance(self.censor_weights, dict) and (\n",
    "        \"fitted_model_0_denominator\" in self.censor_weights or \"fitted_model_numerator\" in self.censor_weights\n",
    "    )\n",
    "    if self.estimand == \"PP\":\n",
    "        if not (isinstance(self.switch_weights, dict) and \"fitted_model_0_denominator\" in self.switch_weights):\n",
    "            raise ValueError(\"Switch weight models are not specified. Use set_switch_weight_model()\")\n",
    "        self._calculate_weights_trial_seq(quiet, switch_weights=True, censor_weights=use_censor_weights)\n",
    "    elif self.estimand == \"ITT\":\n",
    "        self._calculate_weights_trial_seq(quiet, switch_weights=False, censor_weights=use_censor_weights)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown estimand: {self.estimand}\")\n",
    "\n",
    "def _calculate_weights_trial_seq(self, quiet, switch_weights, censor_weights):\n",
    "    if switch_weights:\n",
    "        if not quiet:\n",
    "            print(\"Calculating switch weights...\")\n",
    "        switch_model_0 = self.switch_weights[\"fitted_model_0_denominator\"]\n",
    "        switch_model_1 = self.switch_weights[\"fitted_model_1_denominator\"]\n",
    "        mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "        mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "        self.data.loc[mask_0, \"switch_prob\"] = switch_model_0.predict(self.data[mask_0])\n",
    "        self.data.loc[mask_1, \"switch_prob\"] = switch_model_1.predict(self.data[mask_1])\n",
    "        self.data[\"switch_prob\"] = self.data[\"switch_prob\"].fillna(1.0)\n",
    "        self.data[\"switch_weight\"] = 1 / self.data[\"switch_prob\"]\n",
    "    if censor_weights:\n",
    "        if not quiet:\n",
    "            print(\"Calculating censor weights...\")\n",
    "        if self.estimand == \"PP\":\n",
    "            censor_model_0 = self.censor_weights[\"fitted_model_0_denominator\"]\n",
    "            censor_model_1 = self.censor_weights[\"fitted_model_1_denominator\"]\n",
    "            mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "            mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "            self.data.loc[mask_0, \"censor_prob\"] = censor_model_0.predict(self.data[mask_0])\n",
    "            self.data.loc[mask_1, \"censor_prob\"] = censor_model_1.predict(self.data[mask_1])\n",
    "        elif self.estimand == \"ITT\":\n",
    "            censor_model = self.censor_weights[\"fitted_model_numerator\"]\n",
    "            self.data[\"censor_prob\"] = censor_model.predict(self.data)\n",
    "        self.data[\"censor_prob\"] = self.data[\"censor_prob\"].fillna(1.0)\n",
    "        self.data[\"censor_weight\"] = 1 / self.data[\"censor_prob\"]\n",
    "    if switch_weights and censor_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"switch_weight\"] * self.data[\"censor_weight\"]\n",
    "    elif switch_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"switch_weight\"]\n",
    "    elif censor_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"censor_weight\"]\n",
    "    if \"switch_weight\" in self.data.columns:\n",
    "        print(\"\\nWeight Summary for PP:\")\n",
    "        print(self.data[[\"switch_weight\", \"censor_weight\", \"final_weight\"]].describe())\n",
    "    else:\n",
    "        print(\"\\nWeight Summary for ITT:\")\n",
    "        print(self.data[[\"censor_weight\", \"final_weight\"]].describe())\n",
    "\n",
    "def show_weight_models(self):\n",
    "    if self.switch_weights is None and self.censor_weights is None:\n",
    "        print(\"No weight models have been set.\")\n",
    "        return\n",
    "\n",
    "    if self.estimand == \"PP\":\n",
    "        print(\"===== PP Estimand (No Pooling) =====\")\n",
    "        if self.censor_weights is not None:\n",
    "            print(\"\\n## Informative Censoring Weights ##\")\n",
    "            for prev_treatment in [0, 1]:\n",
    "                for key in [\"numerator\", \"denominator\"]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                    if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                        print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.censor_weights[model_key].summary())\n",
    "        \n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\n## Treatment Switch Weights ##\")\n",
    "            for prev_treatment in [0, 1]:\n",
    "                for key in [\"numerator\", \"denominator\"]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                    if model_key in self.switch_weights and self.switch_weights[model_key] is not None:\n",
    "                        print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.switch_weights[model_key].summary())\n",
    "    \n",
    "    elif self.estimand == \"ITT\":\n",
    "        print(\"===== ITT Estimand =====\")\n",
    "        if self.censor_weights is not None:\n",
    "            print(\"\\n## Informative Censoring Weights ##\")\n",
    "            if \"fitted_model_numerator\" in self.censor_weights and self.censor_weights[\"fitted_model_numerator\"] is not None:\n",
    "                print(\"\\n# Numerator Model (Pooled)\")\n",
    "                print(self.censor_weights[\"fitted_model_numerator\"].summary())\n",
    "            for prev_treatment in [0, 1]:\n",
    "                model_key = f\"fitted_model_{prev_treatment}_denominator\"\n",
    "                if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                    print(f\"\\n# Denominator Model (Previous Treatment = {prev_treatment})\")\n",
    "                    print(self.censor_weights[model_key].summary())\n",
    "\n",
    "TrialSequence.calculate_weights = calculate_weights\n",
    "TrialSequence._calculate_weights_trial_seq = _calculate_weights_trial_seq\n",
    "TrialSequence.show_weight_models = show_weight_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating switch weights...\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for PP:\n",
      "       switch_weight  censor_weight  final_weight\n",
      "count     725.000000     725.000000    725.000000\n",
      "mean        2.733546       1.090906      3.030777\n",
      "std         1.732471       0.070613      2.072097\n",
      "min         1.246125       1.013764      1.329844\n",
      "25%         1.620576       1.048496      1.739213\n",
      "50%         1.955091       1.068877      2.120418\n",
      "75%         3.258089       1.107154      3.581826\n",
      "max        12.525849       1.614490     13.890368\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for ITT:\n",
      "       censor_weight  final_weight\n",
      "count     725.000000    725.000000\n",
      "mean        1.088628      1.088628\n",
      "std         0.044576      0.044576\n",
      "min         1.019809      1.019809\n",
      "25%         1.060133      1.060133\n",
      "50%         1.080359      1.080359\n",
      "75%         1.107915      1.107915\n",
      "max         1.499109      1.499109\n"
     ]
    }
   ],
   "source": [
    "trial_pp.calculate_weights()\n",
    "trial_itt.calculate_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PP Estimand (No Pooling) =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02782\n",
      "Time:                        22:59:34   Log-Likelihood:                -116.34\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.009874\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.3297      0.185     12.625      0.000       1.968       2.691\n",
      "x2            -0.4692      0.184     -2.547      0.011      -0.830      -0.108\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        22:59:34   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02072\n",
      "Time:                        22:59:34   Log-Likelihood:                -79.752\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06621\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6180      0.222     11.796      0.000       2.183       3.053\n",
      "x2            -0.3903      0.210     -1.859      0.063      -0.802       0.021\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        22:59:34   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n",
      "\n",
      "## Treatment Switch Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.05496\n",
      "Time:                        22:59:34   Log-Likelihood:                -232.41\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.001e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7138      0.487      3.520      0.000       0.760       2.668\n",
      "age           -0.0488      0.010     -4.990      0.000      -0.068      -0.030\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      382\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07371\n",
      "Time:                        22:59:34   Log-Likelihood:                -227.80\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.609e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6569      0.520      3.185      0.001       0.637       2.676\n",
      "age           -0.0526      0.010     -5.236      0.000      -0.072      -0.033\n",
      "x1             0.6504      0.230      2.825      0.005       0.199       1.102\n",
      "x3            -0.2106      0.228     -0.923      0.356      -0.658       0.237\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                0.009356\n",
      "Time:                        22:59:34   Log-Likelihood:                -223.10\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04009\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4232      0.475      2.995      0.003       0.492       2.355\n",
      "age           -0.0204      0.010     -2.040      0.041      -0.040      -0.001\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      335\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02034\n",
      "Time:                        22:59:34   Log-Likelihood:                -220.62\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02721\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.0572      0.520      2.033      0.042       0.038       2.077\n",
      "age           -0.0180      0.010     -1.762      0.078      -0.038       0.002\n",
      "x1             0.5117      0.257      1.995      0.046       0.009       1.014\n",
      "x3             0.2281      0.230      0.992      0.321      -0.223       0.679\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_pp.show_weight_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ITT Estimand =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Pooled)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        22:59:34   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.4481      0.141     17.415      0.000       2.173       2.724\n",
      "x2            -0.4486      0.137     -3.278      0.001      -0.717      -0.180\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        22:59:34   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        22:59:34   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_itt.show_weight_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Specify Outcome Model\n",
    "Now we can specify the outcome model. Here we can include adjustment terms for any variables in the dataset. The numerator terms from the stabilised weight models are automatically included in the outcome model formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5\n",
    "def set_outcome_model(self, adjustment_terms=None, model_fitter=None):\n",
    "    if self.data is None:\n",
    "        raise ValueError(\"set_data() before defining the outcome model.\")\n",
    "\n",
    "    # Determine treatment variable\n",
    "    treatment_var = \"treatment\"\n",
    "\n",
    "    # Extract stabilized weight terms\n",
    "    stabilised_weight_terms = []\n",
    "    if self.switch_weights:\n",
    "        stabilised_weight_terms.append(self.switch_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "    if self.censor_weights:\n",
    "        stabilised_weight_terms.append(self.censor_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "\n",
    "    stabilised_weight_terms = \" + \".join(stabilised_weight_terms) if stabilised_weight_terms else \"1\"\n",
    "\n",
    "    # Default adjustment terms based on estimand\n",
    "    if adjustment_terms is None:\n",
    "        adjustment_terms = [\"x1\", \"x2\", \"x3\", \"age\"] if self.estimand == \"PP\" else [\"x2\"]\n",
    "    elif isinstance(adjustment_terms, str):\n",
    "        adjustment_terms = adjustment_terms.split(\" + \")\n",
    "\n",
    "    # Polynomial terms for time effects\n",
    "    additional_terms = []\n",
    "    #if \"followup_time\" in self.data.columns:\n",
    "        #self.data[\"followup_time_squared\"] = self.data[\"followup_time\"] ** 2\n",
    "        # additional_terms.extend([\"followup_time\", \"I(followup_time**2)\"])\n",
    "\n",
    "    # Ensure 'period' and its squared term are included\n",
    "    if \"period\" in self.data.columns:\n",
    "        #self.data[\"period_squared\"] = self.data[\"period\"] ** 2\n",
    "        additional_terms.extend([\"trial_period\", \"I(trial_period**2)\"])\n",
    "\n",
    "    # Ensure unique terms using a set\n",
    "    all_terms = set([treatment_var] + adjustment_terms + additional_terms)\n",
    "    stabilised_terms = set(stabilised_weight_terms.split(\" + \"))  # Convert to set\n",
    "\n",
    "    # Merge while keeping unique terms\n",
    "    final_terms = all_terms | stabilised_terms\n",
    "    final_terms.discard(\"1\")  # Remove placeholder \"1\" if present\n",
    "\n",
    "    # Construct formula\n",
    "    formula = \"outcome ~ \" + \" + \".join(sorted(final_terms))  # Sort for consistency\n",
    "\n",
    "    # Ensure weights exist\n",
    "    if \"final_weight\" not in self.data.columns:\n",
    "        raise ValueError(\"Weights have not been calculated. Run calculate_weights() first.\")\n",
    "\n",
    "    # Default to logistic regression model fitter if none is provided\n",
    "    if model_fitter is None:\n",
    "        model_fitter = stats_glm_logit(save_path=None)\n",
    "\n",
    "    # Store in outcome_model dictionary\n",
    "    self.outcome_model = {\n",
    "        \"formula\": formula,\n",
    "        \"treatment_var\": treatment_var,\n",
    "        \"adjustment_vars\": list(all_terms),  # Store as list for consistency\n",
    "        \"stabilised_weights_terms\": \" + \".join(sorted(stabilised_terms)),  # Keep as string for logging\n",
    "        \"model_fitter\": model_fitter,\n",
    "        \"fitted\": None  # Will be used in Step 8 (fit_msm)\n",
    "    }\n",
    "\n",
    "    return self\n",
    "\n",
    "def show_outcome_model(self):\n",
    "    return self.outcome_model if self.outcome_model else \"Not calculated\"\n",
    "\n",
    "TrialSequence.set_outcome_model = set_outcome_model\n",
    "TrialSequence.show_outcome_model = show_outcome_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': 'outcome ~ I(trial_period**2) + age + treatment + trial_period + x1 + x2 + x3',\n",
       " 'treatment_var': 'treatment',\n",
       " 'adjustment_vars': ['x3',\n",
       "  'x1',\n",
       "  'age',\n",
       "  'I(trial_period**2)',\n",
       "  'trial_period',\n",
       "  'treatment',\n",
       "  'x2'],\n",
       " 'stabilised_weights_terms': 'age + x2',\n",
       " 'model_fitter': <function __main__.stats_glm_logit.<locals>.fit_model(numerator, denominator, data)>,\n",
       " 'fitted': None}"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_pp.set_outcome_model()  \n",
    "trial_itt.set_outcome_model(adjustment_terms=\"x2\")  \n",
    "trial_pp.show_outcome_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expand Trials\n",
    "Now we are ready to create the data set with all of the sequence of target trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_expansion_options(self, output: TEDatastore, chunk_size: int = 0, first_period: int = 0, last_period: float = float('inf'), censor_at_switch: bool = False):\n",
    "    \n",
    "    self.expansion = TEExpansion(chunk_size = chunk_size, datastore = output, first_period = first_period, last_period = last_period, censor_at_switch = censor_at_switch)\n",
    "\n",
    "    return self\n",
    "\n",
    "TrialSequence.set_expansion_options = set_expansion_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x2973eec1be0>"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = TEDatastore()\n",
    "trial_pp.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = True)\n",
    "trial_itt.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Create Sequence of Trials Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_trials(self):\n",
    "    data = self.data.copy()\n",
    "    outcome_adj_vars = self.get_outcome_adjustment_vars()\n",
    "    keeplist = list(set(['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2', 'age'] + outcome_adj_vars))\n",
    "\n",
    "    if 'wt' not in data.columns:\n",
    "        data['wt'] = 1\n",
    "\n",
    "    all_ids = data['id'].unique()\n",
    "    if self.expansion.chunk_size == 0:\n",
    "        ids_split = [all_ids]\n",
    "    else:\n",
    "        ids_split = np.array_split(all_ids, np.ceil(len(all_ids) / self.expansion.chunk_size))\n",
    "\n",
    "    for ids in ids_split:\n",
    "        switch_data = self._expand_chunk(data, ids, outcome_adj_vars, keeplist)\n",
    "        self.expansion.datastore = self.expansion.datastore.save_expanded_data(switch_data)\n",
    "\n",
    "    return self\n",
    "\n",
    "def _expand_chunk(self, data: pd.DataFrame, ids: np.ndarray, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "    chunk_data = data[data['id'].isin(ids)].copy()\n",
    "\n",
    "    first_period = max([self.expansion.first_period, chunk_data[chunk_data['eligible'] == 1]['period'].min() or self.expansion.first_period])\n",
    "    last_period = min([self.expansion.last_period, chunk_data[chunk_data['eligible'] == 1]['period'].max() or self.expansion.last_period])\n",
    "    \n",
    "    expanded_data = []\n",
    "    for _, row in chunk_data.iterrows():\n",
    "        if row['eligible'] == 1 and first_period <= row['period'] <= last_period:\n",
    "            trial_start = row['period']\n",
    "            trial_data = self._generate_trial_instance(row, chunk_data, trial_start, last_period, outcome_adj_vars, keeplist)\n",
    "            expanded_data.append(trial_data)\n",
    "\n",
    "    result = pd.concat(expanded_data, ignore_index=True) if expanded_data else pd.DataFrame()\n",
    "\n",
    "    return result[keeplist]\n",
    "\n",
    "def _generate_trial_instance(self, baseline_row: pd.Series, data: pd.DataFrame, trial_start: int, last_period: float, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "\n",
    "    id_val = baseline_row['id']\n",
    "    patient_data = data[data['id'] == id_val].sort_values('period')\n",
    "    rows = []\n",
    "\n",
    "    if pd.isna(last_period) or last_period == float('inf'):\n",
    "        last_period_value = patient_data['period'].max()\n",
    "    else:\n",
    "        last_period_value = last_period\n",
    "\n",
    "    # Convert float to integer to handle errors\n",
    "    if pd.notna(last_period_value):\n",
    "        last_period_int = int(np.floor(float(last_period_value)))\n",
    "    else:\n",
    "        last_period_int = int(trial_start)\n",
    "\n",
    "    max_period_value = patient_data['period'].max()\n",
    "    if pd.notna(max_period_value):\n",
    "        max_period = int(np.floor(float(max_period_value)))\n",
    "    else:\n",
    "        max_period = last_period_int \n",
    "\n",
    "    last_period_int = int(last_period_int)\n",
    "    max_period = int(max_period)\n",
    "\n",
    "    for period in range(int(trial_start), int(min(last_period_int + 1, max_period + 1))):\n",
    "        period_row = patient_data[patient_data['period'] == period].iloc[0] if not patient_data[patient_data['period'] == period].empty else None\n",
    "        \n",
    "        if period_row is None:\n",
    "            continue\n",
    "\n",
    "        if self.expansion.censor_at_switch and period > trial_start:\n",
    "            prev_row = patient_data[patient_data['period'] == (period - 1)].iloc[0]\n",
    "            if prev_row['treatment'] != period_row['treatment']:\n",
    "                break  # Censor at switch\n",
    "\n",
    "        trial_period = period - trial_start\n",
    "        followup_time = period - trial_start\n",
    "        final_weight = self.data[(self.data['id'] == id_val) & (self.data['period'] == period)]['final_weight'].iloc[0] if not self.data[(self.data['id'] == id_val) & (self.data['period'] == period)].empty else 1.0\n",
    "        row_dict = {\n",
    "            'id': id_val,\n",
    "            'trial_period': trial_period,\n",
    "            'followup_time': followup_time,\n",
    "            'outcome': period_row['outcome'],\n",
    "            'weight': final_weight,  \n",
    "            'treatment': period_row['treatment'],\n",
    "        }\n",
    "        \n",
    "        for var in outcome_adj_vars + ['age', 'x2']:\n",
    "            if var in patient_data.columns:\n",
    "                row_dict[var] = period_row.get(var, np.nan)\n",
    "            else:\n",
    "                row_dict[var] = np.nan \n",
    "\n",
    "        rows.append(pd.Series(row_dict))\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    int_columns = ['id', 'trial_period', 'followup_time', 'outcome', 'treatment', 'age']\n",
    "    df[int_columns] = df[int_columns].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_outcome_adjustment_vars(self):\n",
    "    return getattr(self.outcome_model, 'adjustment_vars', [])\n",
    "\n",
    "\n",
    "TrialSequence.expand_trials = expand_trials\n",
    "TrialSequence._expand_chunk = _expand_chunk\n",
    "TrialSequence._generate_trial_instance = _generate_trial_instance\n",
    "TrialSequence.get_outcome_adjustment_vars = get_outcome_adjustment_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanded Data:\n",
      "Index(['followup_time', 'age', 'trial_period', 'id', 'treatment', 'x2',\n",
      "       'outcome', 'weight'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trial_pp.expand_trials()\n",
    "trial_itt.expand_trials()\n",
    "print(\"\\nExpanded Data:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load or Sample Expanded Data\n",
    "Now that the expanded data has been created, we can prepare the data to fit the outcome model. For data that can fit comfortably in memory, this is a trivial step using load_expanded_data.\n",
    "\n",
    "For large datasets, it may be necessary to sample from the expanded by setting the p_control argument. This sets the probability that an observation with outcome == 0 will be included in the loaded data. A seed can be set for reproducibility. Additionally, a vector of periods to include can be specified, e.g., period = 1:60, and/or a subsetting condition, subset_condition = \"age > 65\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expanded_data(self, p_control: Optional[float] = None, period: Optional[List[int]] = None, subset_condition: Optional[str] = None, seed: Optional[int] = None):\n",
    "    \n",
    "    if p_control is None:\n",
    "        data_table = self.expansion.datastore.data.copy()\n",
    "        data_table['sample_weight'] = 1\n",
    "    else:\n",
    "        np.random.seed(seed) if seed is not None else np.random.seed()\n",
    "        data_table = self.expansion.datastore.data.copy()\n",
    "\n",
    "        mask_outcome_1 = data_table['outcome'] == 1\n",
    "        mask_outcome_0 = data_table['outcome'] == 0\n",
    "        sampled_0 = data_table[mask_outcome_0].sample(frac=p_control, replace=False)\n",
    "        data_table = pd.concat([data_table[mask_outcome_1], sampled_0])\n",
    "\n",
    "        data_table.loc[mask_outcome_0, 'sample_weight'] = 1 / p_control if p_control > 0 else 1\n",
    "        data_table.loc[mask_outcome_1, 'sample_weight'] = 1\n",
    "\n",
    "    if period is not None:\n",
    "        data_table = data_table[data_table['trial_period'].isin(period) | data_table['followup_time'].isin(period)]\n",
    "    \n",
    "    if subset_condition is not None:\n",
    "        data_table = data_table.query(subset_condition)\n",
    "    \n",
    "    data_table = data_table.sort_values(['id', 'trial_period', 'followup_time'])\n",
    "    data_table = data_table.reset_index(drop=True)\n",
    "    \n",
    "    self.outcome_data = data_table\n",
    "    \n",
    "    return self\n",
    "\n",
    "TrialSequence.load_expanded_data = load_expanded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in self.outcome_data: ['followup_time', 'age', 'trial_period', 'id', 'treatment', 'x2', 'outcome', 'weight', 'sample_weight']\n"
     ]
    }
   ],
   "source": [
    "trial_pp.load_expanded_data(p_control = 0.5, seed=1234)\n",
    "trial_itt.load_expanded_data(p_control = 0.5, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fit Marginal Structural Model\n",
    "To fit the outcome model we use fit_msm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_msm(self, weight_cols=[\"weight\"], modify_weights=None, family=\"binomial\"):\n",
    "    if not self.outcome_model:\n",
    "        raise ValueError(\"Outcome model not defined. Run set_outcome_model() first.\")\n",
    "    \n",
    "    formula = self.outcome_model[\"formula\"]\n",
    "    print(f\"Using formula from set_outcome_model: {formula}\")\n",
    "    \n",
    "    weight_col = next(col for col in weight_cols if col in self.outcome_data.columns)\n",
    "    data = self.outcome_data[~self.outcome_data[weight_col].isna()].copy()\n",
    "    weights = data[weight_col].values\n",
    "    \n",
    "    if modify_weights:\n",
    "        weights = modify_weights(weights)\n",
    "    \n",
    "    # Fit the MSM\n",
    "    try:\n",
    "        if family == \"binomial\":\n",
    "            model = smf.logit(formula, data=data)\n",
    "            fitted_model = model.fit(method='lbfgs', weights=weights, disp=0, maxiter=100)\n",
    "        elif family == \"gaussian\":\n",
    "            model = smf.ols(formula, data=data, weights=weights)\n",
    "            fitted_model = model.fit()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported family. Use 'binomial' or 'gaussian'.\")\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        raise ValueError(f\"Model fitting failed due to singular matrix: {e}.\")\n",
    "    \n",
    "    print(\"MSM Fit Summary:\")\n",
    "    print(fitted_model.summary())\n",
    "    self.outcome_model[\"fitted\"] = fitted_model\n",
    "    return fitted_model\n",
    "\n",
    "TrialSequence.fit_msm = fit_msm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using formula from set_outcome_model: outcome ~ I(trial_period**2) + treatment + trial_period + x2\n",
      "MSM Fit Summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                outcome   No. Observations:                  970\n",
      "Model:                          Logit   Df Residuals:                      965\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.01472\n",
      "Time:                        22:59:38   Log-Likelihood:                -80.342\n",
      "converged:                       True   LL-Null:                       -81.543\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.6625\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -4.4163      0.570     -7.746      0.000      -5.534      -3.299\n",
      "I(trial_period ** 2)    -0.0086      0.012     -0.720      0.472      -0.032       0.015\n",
      "treatment               -0.3057      0.545     -0.560      0.575      -1.375       0.763\n",
      "trial_period             0.1617      0.180      0.897      0.370      -0.192       0.515\n",
      "x2                       0.2741      0.259      1.059      0.290      -0.233       0.782\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:19: FutureWarning: Keyword arguments have been passed to the optimizer that have no effect. The list of allowed keyword arguments for method lbfgs is: m, pgtol, factr, maxfun, epsilon, approx_grad, bounds, loglike_and_score, iprint. The list of unsupported keyword arguments passed include: weights. After release 0.14, this will raise.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973f203c50>"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def winsorize_weights(weights):\n",
    "    #99th percentile values\n",
    "    return np.minimum(weights, np.quantile(weights, 0.99, method='nearest'))\n",
    "\n",
    "trial_itt.fit_msm(weight_cols=[\"weight\"], modify_weights=winsorize_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Inference\n",
    "We use the predict() method to estimate survival probabilities or cumulative incidences for different values of assigned_treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, newdata=None, predict_times=None, type=\"survival\"):\n",
    "    \n",
    "    if newdata is None:\n",
    "        if self.outcome_data is None:\n",
    "            raise ValueError(\"outcome_data not available. Run load_expanded_data() first.\")\n",
    "        data = self.outcome_data.copy()\n",
    "    else:\n",
    "        data = newdata.copy()\n",
    "    \n",
    "    if predict_times is None:\n",
    "        predict_times = np.arange(0, 11)\n",
    "    \n",
    "    predict_times = np.array(predict_times, dtype=int)\n",
    "    \n",
    "    model = self.outcome_model[\"fitted\"]\n",
    "    \n",
    "    data_control = data.copy()\n",
    "    data_control[\"treatment\"] = 0  # Control group\n",
    "    \n",
    "    data_treated = data.copy()\n",
    "    data_treated[\"treatment\"] = 1  # Treated group\n",
    "    \n",
    "    # Predict probabilities for all data, then filter by predict_times\n",
    "    preds_control = model.predict(data_control)\n",
    "    preds_treated = model.predict(data_treated)\n",
    "    \n",
    "    survival_control = 1 - pd.Series(preds_control).groupby(data_control[\"followup_time\"]).mean()\n",
    "    survival_treated = 1 - pd.Series(preds_treated).groupby(data_treated[\"followup_time\"]).mean()\n",
    "    \n",
    "    survival_diff = (survival_treated.reindex(predict_times).ffill().fillna(0) - survival_control.reindex(predict_times).ffill().fillna(0))\n",
    "    \n",
    "    ci_lower = survival_diff - 1.96 * np.std(survival_diff)\n",
    "    ci_upper = survival_diff + 1.96 * np.std(survival_diff)\n",
    "    \n",
    "    # Step graph was ugly so we let gpt generate a smoother curve AHAHAHA\n",
    "    fine_times = np.linspace(predict_times.min(), predict_times.max(), 100)\n",
    "    \n",
    "    interp_diff = interp1d(predict_times, survival_diff, kind='cubic', fill_value=\"extrapolate\")\n",
    "    interp_lower = interp1d(predict_times, ci_lower, kind='cubic', fill_value=\"extrapolate\")\n",
    "    interp_upper = interp1d(predict_times, ci_upper, kind='cubic', fill_value=\"extrapolate\")\n",
    "    \n",
    "    smooth_diff = interp_diff(fine_times)\n",
    "    smooth_lower = interp_lower(fine_times)\n",
    "    smooth_upper = interp_upper(fine_times)\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(fine_times, smooth_diff, label=\"Survival Difference\", color=\"blue\")\n",
    "    plt.plot(fine_times, smooth_lower, linestyle='--', color=\"red\", label=\"95% CI Lower Bound\")\n",
    "    plt.plot(fine_times, smooth_upper, linestyle='--', color=\"red\", label=\"95% CI Upper Bound\")\n",
    "    \n",
    "    plt.xlabel(\"Follow-up Time\")\n",
    "    plt.ylabel(\"Survival Difference\")\n",
    "    plt.title(\"Predicted Survival Difference Over Time\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "TrialSequence.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial_itt.predict(type=\"difference\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
