{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 for Clustering: Target Trial Emulation\n",
    "- New and novel methods in Machine Learning are made either by borrowing formulas and concepts from other scientific fields and redefining it based on new sets of assumptions, or by adding an extra step to an already existing framework of methodology.\n",
    "\n",
    "- In this exercise (Assignment 1 of the Clustering Topic), we will try to develop a novel method of Target Trial Emulation by integrating concepts of Clustering into the already existing framework. Target Trial Emulation is a new methodological framework in epidemiology which tries to account for the biases in old and traditional designs.\n",
    "\n",
    "These are the instructions:\n",
    "1. Look at this website: https://rpubs.com/alanyang0924/TTE\n",
    "2. Extract the dummy data in the package and save it as \"data_censored.csv\"\n",
    "2. Convert the R codes into Python Codes (use Jupyter Notebook), replicate the results using your python code.\n",
    "3. Create another copy of your Python Codes, name it TTE-v2 (use Jupyter Notebook).\n",
    "4. Using TTE-v2, think of a creative way on where you would integrate a clustering mechanism, understand each step carefully and decide at which step a clustering method can be implemented. Generate insights from your results.\n",
    "5. Do this by pair, preferably your thesis partner.\n",
    "6. Push to your github repository.\n",
    "7. Deadline is: February 28, 2025 at 11:59 pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import patsy\n",
    "import joblib\n",
    "import json\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import logit\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Class Definition and Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_glm_logit(save_path):\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    def fit_model(numerator, denominator, data):\n",
    "        formula = numerator\n",
    "        try:\n",
    "            model = smf.logit(formula, data).fit(disp=0)  # Suppress convergence messages\n",
    "        except (np.linalg.LinAlgError, sm.tools.sm_exceptions.PerfectSeparationError):\n",
    "            print(f\"Warning: Perfect separation or singular matrix detected for {formula}. Falling back to intercept-only model.\")\n",
    "            formula = f\"{formula.split('~')[0].strip()} ~ 1\"\n",
    "            model = smf.logit(formula, data).fit(disp=0)\n",
    "        model_path = os.path.join(save_path, \"logit_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "        model_details = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"model_type\": \"te_stats_glm_logit\",\n",
    "            \"file_path\": model_path\n",
    "        }\n",
    "        json.dump(model_details, open(os.path.join(save_path, \"model_details.json\"), \"w\"))\n",
    "        return model\n",
    "    \n",
    "    return fit_model\n",
    "\n",
    "@dataclass\n",
    "class TEDatastore:\n",
    "    data: pd.DataFrame = None\n",
    "\n",
    "    def save_expanded_data(self, switch_data: pd.DataFrame):\n",
    "        if self.data is None:\n",
    "            self.data = switch_data\n",
    "        else:\n",
    "            self.data = pd.concat([self.data, switch_data], ignore_index=True)\n",
    "        return self\n",
    "\n",
    "@dataclass\n",
    "class TEExpansion:\n",
    "    chunk_size: int = 0\n",
    "    datastore: TEDatastore = None\n",
    "    first_period: int = 0\n",
    "    last_period: float = float('inf')\n",
    "    censor_at_switch: bool = False\n",
    "\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand, **kwargs):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = None\n",
    "        self.outcome_model = None\n",
    "        self.expansion = None\n",
    "        self.outcome_data = None\n",
    "\n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        self.data[\"followup_time\"] = self.data.groupby(\"id\")[\"period\"].transform(\n",
    "            lambda x: x[(self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)].min()\n",
    "            if ((self.data.loc[x.index, \"censored\"] == 1) | (self.data.loc[x.index, \"outcome\"] == 1)).any()\n",
    "            else x.max()\n",
    "        )\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"Trial Sequence Object\\nEstimand: {self.estimand}\\n\")\n",
    "        if self.data is not None:\n",
    "            display(self.data)\n",
    "        else:\n",
    "            print(\"No data set\")\n",
    "        print(\"\\nIPW for informative censoring:\")\n",
    "        print(self.censor_weights if self.censor_weights is not None else \"Not calculated.\")\n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\nIPW for treatment switch censoring:\")\n",
    "            print(self.switch_weights)\n",
    "        print(\"\\nOutcome model:\")\n",
    "        print(self.outcome_model if self.outcome_model is not None else \"Not specified.\")\n",
    "        if self.outcome_data is not None:\n",
    "            print(\"\\nOutcome data:\")\n",
    "            print(self.outcome_data)\n",
    "    \n",
    "\n",
    "#Subclass of Trial Sequence, handles the PP (hehe) estimand\n",
    "class TrialSequencePP(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"PP\", **kwargs)\n",
    " \n",
    "#Subclass of Trial Sequence, handles the ITT estimand\n",
    "class TrialSequenceITT(TrialSequence):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"ITT\", **kwargs)\n",
    "\n",
    "#trial_sequence function equivalent used in the article\n",
    "def trial_sequence(estimand, **kwargs):\n",
    "    estimand_classes = {\n",
    "        \"PP\": TrialSequencePP,\n",
    "        \"ITT\": TrialSequenceITT\n",
    "    }\n",
    "\n",
    "    if estimand not in estimand_classes:\n",
    "        raise ValueError(f\"{estimand} is not a valid estimand, choose either PP or ITT\")\n",
    "    \n",
    "    return estimand_classes[estimand](**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "A sequence of target trials analysis starts by specifying which estimand will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_pp = trial_sequence(\"PP\")\n",
    "trial_itt = trial_sequence(\"ITT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preparation\n",
    "Next the user must specify the observational input data that will be used for the target trial emulation. Here we need to specify which columns contain which values and how they should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Dummy Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  \n",
       "0          0         0         1  \n",
       "1          0         0         0  \n",
       "2          0         0         0  \n",
       "3          0         0         0  \n",
       "4          0         0         0  \n",
       "..       ...       ...       ...  \n",
       "720        0         0         0  \n",
       "721        0         0         0  \n",
       "722        0         0         0  \n",
       "723        0         0         0  \n",
       "724        1         0         0  \n",
       "\n",
       "[725 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Sequence Object\n",
      "Estimand: PP\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n",
      "Trial Sequence Object\n",
      "Estimand: ITT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>treatment</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>age</th>\n",
       "      <th>age_s</th>\n",
       "      <th>outcome</th>\n",
       "      <th>censored</th>\n",
       "      <th>eligible</th>\n",
       "      <th>previous_treatment</th>\n",
       "      <th>followup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.146148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>36</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>37</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.481762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>40</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.747906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>68</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.790056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>69</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387429</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>70</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.033762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>71</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.340497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575268</td>\n",
       "      <td>72</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  period  treatment  x1        x2  x3        x4  age     age_s  \\\n",
       "0     1       0          1   1  1.146148   0  0.734203   36  0.083333   \n",
       "1     1       1          1   1  0.002200   0  0.734203   37  0.166667   \n",
       "2     1       2          1   0 -0.481762   0  0.734203   38  0.250000   \n",
       "3     1       3          1   0  0.007872   0  0.734203   39  0.333333   \n",
       "4     1       4          1   1  0.216054   0  0.734203   40  0.416667   \n",
       "..   ..     ...        ...  ..       ...  ..       ...  ...       ...   \n",
       "720  99       3          0   0 -0.747906   1  0.575268   68  2.750000   \n",
       "721  99       4          0   0 -0.790056   1  0.575268   69  2.833333   \n",
       "722  99       5          1   1  0.387429   1  0.575268   70  2.916667   \n",
       "723  99       6          1   1 -0.033762   1  0.575268   71  3.000000   \n",
       "724  99       7          0   0 -1.340497   1  0.575268   72  3.083333   \n",
       "\n",
       "     outcome  censored  eligible  previous_treatment  followup_time  \n",
       "0          0         0         1                 0.0              5  \n",
       "1          0         0         0                 1.0              5  \n",
       "2          0         0         0                 1.0              5  \n",
       "3          0         0         0                 1.0              5  \n",
       "4          0         0         0                 1.0              5  \n",
       "..       ...       ...       ...                 ...            ...  \n",
       "720        0         0         0                 0.0              7  \n",
       "721        0         0         0                 0.0              7  \n",
       "722        0         0         0                 0.0              7  \n",
       "723        0         0         0                 1.0              7  \n",
       "724        1         0         0                 1.0              7  \n",
       "\n",
       "[725 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPW for informative censoring:\n",
      "Not calculated.\n",
      "\n",
      "Outcome model:\n",
      "Not specified.\n"
     ]
    }
   ],
   "source": [
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Extracted Dummy Data\")\n",
    "display(data_censored)\n",
    "data_censored[\"previous_treatment\"] = data_censored[\"treatment\"].shift(1).fillna(0)\n",
    "#Setting the dataset to the data field\n",
    "trial_pp.set_data(data_censored.copy())  # Create a separate copy\n",
    "trial_itt.set_data(data_censored.copy())  \n",
    "\n",
    "\n",
    "#Displaying the info stored in each class\n",
    "trial_pp.show()\n",
    "\n",
    "trial_itt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Weight Models\n",
    "To adjust for the effects of informative censoring, inverse probability of censoring weights (IPCW) can be applied. To estimate these weights, we construct time-to-(censoring) event models. Two sets of models are fit for the two censoring mechanisms which may apply: censoring due to deviation from assigned treatment and other informative censoring.\n",
    "#### 3.1 Censoring due to treatment switching\n",
    "We specify model formulas to be used for calculating the probability of receiving treatment in the current period. Separate models are fitted for patients who had treatment = 1 and those who had treatment = 0 in the previous period. Stabilized weights are used by fitting numerator and denominator models.\n",
    "\n",
    "There are optional arguments to specify columns which can include/exclude observations from the treatment models. These are used in case it is not possible for a patient to deviate from a certain treatment assignment in that period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_switch_weight_model(self, numerator=None, denominator=None, model_fitter=None, eligible_wts_0=None, eligible_wts_1=None):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"set_data() before setting switch weight models\")\n",
    "        if self.estimand == \"ITT\":\n",
    "            raise ValueError(\"Switching weights are not supported for intention-to-treat analyses\")\n",
    "        if eligible_wts_0 and eligible_wts_0 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_0: \"eligible_wts_0\"})\n",
    "        if eligible_wts_1 and eligible_wts_1 in self.data.columns:\n",
    "            self.data = self.data.rename(columns={eligible_wts_1: \"eligible_wts_1\"})\n",
    "        if numerator is None:\n",
    "            numerator = \"1\"\n",
    "        if denominator is None:\n",
    "            denominator = \"1\"\n",
    "        if \"time_on_regime\" in denominator:\n",
    "            raise ValueError(\"time_on_regime should not be used in denominator.\")\n",
    "        formula_numerator = f\"treatment ~ {numerator}\"\n",
    "        formula_denominator = f\"treatment ~ {denominator}\"\n",
    "        self.switch_weights = {\n",
    "            \"numerator\": formula_numerator,\n",
    "            \"denominator\": formula_denominator,\n",
    "            \"model_fitter\": \"te_stats_glm_logit\",\n",
    "        }\n",
    "        if model_fitter is not None:\n",
    "            self.switch_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.switch_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.switch_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_prob_0\"] = self.switch_weights[\"fitted_model_0_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.data[\"switch_prob_1\"] = self.switch_weights[\"fitted_model_1_denominator\"].predict(self.data[self.data[\"previous_treatment\"] == 1])\n",
    "            self.data[\"switch_weight\"] = np.where(self.data[\"previous_treatment\"] == 0, \n",
    "                                                  1 / self.data[\"switch_prob_0\"], \n",
    "                                                  1 / self.data[\"switch_prob_1\"])\n",
    "            self.data[\"switch_weight\"] = self.data[\"switch_weight\"].fillna(1)\n",
    "            print(\"Switch weights computed and stored in self.data\")\n",
    "\n",
    "def show_switch_weights(self):\n",
    "    return self.switch_weights if self.switch_weights else \"Not calculated\"\n",
    "    \n",
    "TrialSequence.set_switch_weight_model = set_switch_weight_model\n",
    "TrialSequence.show_switch_weights = show_switch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switch weights computed and stored in self.data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'numerator': 'treatment ~ age',\n",
       " 'denominator': 'treatment ~ age + x1 + x3',\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973974ea50>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d323e30>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d1b9d90>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d1bb5f0>}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Models\"\n",
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_switch_weight_model(numerator=\"age\", denominator=\"age + x1 + x3\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"switch_models\")))\n",
    "trial_pp.show_switch_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Other informative censoring\n",
    "In case there is other informative censoring occurring in the data, we can create similar models to estimate the IPCW. These can be used with all types of estimand. We need to specifycensor_event which is the column containing the censoring indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_censor_weight_model(self, censor_event, numerator=\"1\", denominator=\"1\", pool_models=\"none\", model_fitter=None):\n",
    "    if model_fitter is None:\n",
    "        model_fitter = stats_glm_logit()\n",
    "    if censor_event not in self.data.columns:\n",
    "        raise ValueError(f\"'{censor_event}' must be a column in the dataset.\")\n",
    "    self.data[\"censored_inv\"] = 1 - self.data[censor_event]\n",
    "    formula_numerator = f\"censored_inv ~ {numerator}\"\n",
    "    formula_denominator = f\"censored_inv ~ {denominator}\"\n",
    "    self.censor_weights = {\n",
    "        \"numerator\": formula_numerator,\n",
    "        \"denominator\": formula_denominator,\n",
    "        \"pool_numerator\": pool_models in [\"numerator\", \"both\"],\n",
    "        \"pool_denominator\": pool_models == \"both\",\n",
    "        \"model_fitter\": \"te_stats_glm_logit\"\n",
    "    }\n",
    "    if self.estimand == \"PP\":\n",
    "        self.censor_weights[\"fitted_model_0_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "        self.censor_weights[\"fitted_model_1_numerator\"] = model_fitter(formula_numerator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "        self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "        self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "    elif self.estimand == \"ITT\":\n",
    "        self.censor_weights[\"fitted_model_numerator\"] = model_fitter(formula_numerator, denominator, self.data)\n",
    "        if not self.censor_weights[\"pool_denominator\"]:\n",
    "            self.censor_weights[\"fitted_model_0_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 0])\n",
    "            self.censor_weights[\"fitted_model_1_denominator\"] = model_fitter(formula_denominator, denominator, self.data[self.data[\"previous_treatment\"] == 1])\n",
    "\n",
    "def show_censor_weights(self):\n",
    "    return self.censor_weights if self.censor_weights else \"Not calculated\"\n",
    "\n",
    "\n",
    "TrialSequence.set_censor_weight_model = set_censor_weight_model\n",
    "TrialSequence.show_censor_weights = show_censor_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': False,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_0_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d1c7e30>,\n",
       " 'fitted_model_1_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973cea3830>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d352090>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973cdd3290>}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_pp.data[trial_pp.data[\"previous_treatment\"] == 1]\n",
    "trial_pp.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"none\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_pp.show_censor_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerator': 'censored_inv ~ x2',\n",
       " 'denominator': 'censored_inv ~ x2 + x1',\n",
       " 'pool_numerator': True,\n",
       " 'pool_denominator': False,\n",
       " 'model_fitter': 'te_stats_glm_logit',\n",
       " 'fitted_model_numerator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d3230b0>,\n",
       " 'fitted_model_0_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973d1ee810>,\n",
       " 'fitted_model_1_denominator': <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x2973cf3d790>}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 0]\n",
    "data_1 = trial_itt.data[trial_itt.data[\"previous_treatment\"] == 1]\n",
    "trial_itt.set_censor_weight_model(censor_event=\"censored\", numerator=\"x2\", denominator=\"x2 + x1\", pool_models=\"numerator\", model_fitter=stats_glm_logit(save_path=os.path.join(path, \"censor_models\")))\n",
    "trial_itt.show_censor_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate Weights\n",
    "Next we need to fit the individual models and combine them into weights. This is done with calculate_weights()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(self, quiet=False):\n",
    "    use_censor_weights = isinstance(self.censor_weights, dict) and (\n",
    "        \"fitted_model_0_denominator\" in self.censor_weights or \"fitted_model_numerator\" in self.censor_weights\n",
    "    )\n",
    "    if self.estimand == \"PP\":\n",
    "        if not (isinstance(self.switch_weights, dict) and \"fitted_model_0_denominator\" in self.switch_weights):\n",
    "            raise ValueError(\"Switch weight models are not specified. Use set_switch_weight_model()\")\n",
    "        self._calculate_weights_trial_seq(quiet, switch_weights=True, censor_weights=use_censor_weights)\n",
    "    elif self.estimand == \"ITT\":\n",
    "        self._calculate_weights_trial_seq(quiet, switch_weights=False, censor_weights=use_censor_weights)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown estimand: {self.estimand}\")\n",
    "\n",
    "def _calculate_weights_trial_seq(self, quiet, switch_weights, censor_weights):\n",
    "    if switch_weights:\n",
    "        if not quiet:\n",
    "            print(\"Calculating switch weights...\")\n",
    "        switch_model_0 = self.switch_weights[\"fitted_model_0_denominator\"]\n",
    "        switch_model_1 = self.switch_weights[\"fitted_model_1_denominator\"]\n",
    "        mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "        mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "        self.data.loc[mask_0, \"switch_prob\"] = switch_model_0.predict(self.data[mask_0])\n",
    "        self.data.loc[mask_1, \"switch_prob\"] = switch_model_1.predict(self.data[mask_1])\n",
    "        self.data[\"switch_prob\"] = self.data[\"switch_prob\"].fillna(1.0)\n",
    "        self.data[\"switch_weight\"] = 1 / self.data[\"switch_prob\"]\n",
    "    if censor_weights:\n",
    "        if not quiet:\n",
    "            print(\"Calculating censor weights...\")\n",
    "        if self.estimand == \"PP\":\n",
    "            censor_model_0 = self.censor_weights[\"fitted_model_0_denominator\"]\n",
    "            censor_model_1 = self.censor_weights[\"fitted_model_1_denominator\"]\n",
    "            mask_0 = self.data[\"previous_treatment\"] == 0\n",
    "            mask_1 = self.data[\"previous_treatment\"] == 1\n",
    "            self.data.loc[mask_0, \"censor_prob\"] = censor_model_0.predict(self.data[mask_0])\n",
    "            self.data.loc[mask_1, \"censor_prob\"] = censor_model_1.predict(self.data[mask_1])\n",
    "        elif self.estimand == \"ITT\":\n",
    "            censor_model = self.censor_weights[\"fitted_model_numerator\"]\n",
    "            self.data[\"censor_prob\"] = censor_model.predict(self.data)\n",
    "        self.data[\"censor_prob\"] = self.data[\"censor_prob\"].fillna(1.0)\n",
    "        self.data[\"censor_weight\"] = 1 / self.data[\"censor_prob\"]\n",
    "    if switch_weights and censor_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"switch_weight\"] * self.data[\"censor_weight\"]\n",
    "    elif switch_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"switch_weight\"]\n",
    "    elif censor_weights:\n",
    "        self.data[\"final_weight\"] = self.data[\"censor_weight\"]\n",
    "    if \"switch_weight\" in self.data.columns:\n",
    "        print(\"\\nWeight Summary for PP:\")\n",
    "        print(self.data[[\"switch_weight\", \"censor_weight\", \"final_weight\"]].describe())\n",
    "    else:\n",
    "        print(\"\\nWeight Summary for ITT:\")\n",
    "        print(self.data[[\"censor_weight\", \"final_weight\"]].describe())\n",
    "\n",
    "def show_weight_models(self):\n",
    "    if self.switch_weights is None and self.censor_weights is None:\n",
    "        print(\"No weight models have been set.\")\n",
    "        return\n",
    "\n",
    "    if self.estimand == \"PP\":\n",
    "        print(\"===== PP Estimand (No Pooling) =====\")\n",
    "        if self.censor_weights is not None:\n",
    "            print(\"\\n## Informative Censoring Weights ##\")\n",
    "            for prev_treatment in [0, 1]:\n",
    "                for key in [\"numerator\", \"denominator\"]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                    if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                        print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.censor_weights[model_key].summary())\n",
    "        \n",
    "        if self.switch_weights is not None:\n",
    "            print(\"\\n## Treatment Switch Weights ##\")\n",
    "            for prev_treatment in [0, 1]:\n",
    "                for key in [\"numerator\", \"denominator\"]:\n",
    "                    model_key = f\"fitted_model_{prev_treatment}_{key}\"\n",
    "                    if model_key in self.switch_weights and self.switch_weights[model_key] is not None:\n",
    "                        print(f\"\\n# {key.title()} Model (Previous Treatment = {prev_treatment})\")\n",
    "                        print(self.switch_weights[model_key].summary())\n",
    "    \n",
    "    elif self.estimand == \"ITT\":\n",
    "        print(\"===== ITT Estimand =====\")\n",
    "        if self.censor_weights is not None:\n",
    "            print(\"\\n## Informative Censoring Weights ##\")\n",
    "            if \"fitted_model_numerator\" in self.censor_weights and self.censor_weights[\"fitted_model_numerator\"] is not None:\n",
    "                print(\"\\n# Numerator Model (Pooled)\")\n",
    "                print(self.censor_weights[\"fitted_model_numerator\"].summary())\n",
    "            for prev_treatment in [0, 1]:\n",
    "                model_key = f\"fitted_model_{prev_treatment}_denominator\"\n",
    "                if model_key in self.censor_weights and self.censor_weights[model_key] is not None:\n",
    "                    print(f\"\\n# Denominator Model (Previous Treatment = {prev_treatment})\")\n",
    "                    print(self.censor_weights[model_key].summary())\n",
    "\n",
    "TrialSequence.calculate_weights = calculate_weights\n",
    "TrialSequence._calculate_weights_trial_seq = _calculate_weights_trial_seq\n",
    "TrialSequence.show_weight_models = show_weight_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating switch weights...\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for PP:\n",
      "       switch_weight  censor_weight  final_weight\n",
      "count     725.000000     725.000000    725.000000\n",
      "mean        2.733546       1.090906      3.030777\n",
      "std         1.732471       0.070613      2.072097\n",
      "min         1.246125       1.013764      1.329844\n",
      "25%         1.620576       1.048496      1.739213\n",
      "50%         1.955091       1.068877      2.120418\n",
      "75%         3.258089       1.107154      3.581826\n",
      "max        12.525849       1.614490     13.890368\n",
      "Calculating censor weights...\n",
      "\n",
      "Weight Summary for ITT:\n",
      "       censor_weight  final_weight\n",
      "count     725.000000    725.000000\n",
      "mean        1.088628      1.088628\n",
      "std         0.044576      0.044576\n",
      "min         1.019809      1.019809\n",
      "25%         1.060133      1.060133\n",
      "50%         1.080359      1.080359\n",
      "75%         1.107915      1.107915\n",
      "max         1.499109      1.499109\n"
     ]
    }
   ],
   "source": [
    "trial_pp.calculate_weights()\n",
    "trial_itt.calculate_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PP Estimand (No Pooling) =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02782\n",
      "Time:                        21:27:38   Log-Likelihood:                -116.34\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.009874\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.3297      0.185     12.625      0.000       1.968       2.691\n",
      "x2            -0.4692      0.184     -2.547      0.011      -0.830      -0.108\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        21:27:38   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02072\n",
      "Time:                        21:27:38   Log-Likelihood:                -79.752\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.06621\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6180      0.222     11.796      0.000       2.183       3.053\n",
      "x2            -0.3903      0.210     -1.859      0.063      -0.802       0.021\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        21:27:38   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n",
      "\n",
      "## Treatment Switch Weights ##\n",
      "\n",
      "# Numerator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      384\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.05496\n",
      "Time:                        21:27:38   Log-Likelihood:                -232.41\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.001e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7138      0.487      3.520      0.000       0.760       2.668\n",
      "age           -0.0488      0.010     -4.990      0.000      -0.068      -0.030\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      382\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07371\n",
      "Time:                        21:27:38   Log-Likelihood:                -227.80\n",
      "converged:                       True   LL-Null:                       -245.92\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.609e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6569      0.520      3.185      0.001       0.637       2.676\n",
      "age           -0.0526      0.010     -5.236      0.000      -0.072      -0.033\n",
      "x1             0.6504      0.230      2.825      0.005       0.199       1.102\n",
      "x3            -0.2106      0.228     -0.923      0.356      -0.658       0.237\n",
      "==============================================================================\n",
      "\n",
      "# Numerator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      337\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                0.009356\n",
      "Time:                        21:27:38   Log-Likelihood:                -223.10\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.04009\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4232      0.475      2.995      0.003       0.492       2.355\n",
      "age           -0.0204      0.010     -2.040      0.041      -0.040      -0.001\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              treatment   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      335\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02034\n",
      "Time:                        21:27:38   Log-Likelihood:                -220.62\n",
      "converged:                       True   LL-Null:                       -225.21\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.02721\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.0572      0.520      2.033      0.042       0.038       2.077\n",
      "age           -0.0180      0.010     -1.762      0.078      -0.038       0.002\n",
      "x1             0.5117      0.257      1.995      0.046       0.009       1.014\n",
      "x3             0.2281      0.230      0.992      0.321      -0.223       0.679\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_pp.show_weight_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ITT Estimand =====\n",
      "\n",
      "## Informative Censoring Weights ##\n",
      "\n",
      "# Numerator Model (Pooled)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  725\n",
      "Model:                          Logit   Df Residuals:                      723\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02676\n",
      "Time:                        21:27:38   Log-Likelihood:                -196.70\n",
      "converged:                       True   LL-Null:                       -202.11\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.001007\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.4481      0.141     17.415      0.000       2.173       2.724\n",
      "x2            -0.4486      0.137     -3.278      0.001      -0.717      -0.180\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 0)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  386\n",
      "Model:                          Logit   Df Residuals:                      383\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.07199\n",
      "Time:                        21:27:38   Log-Likelihood:                -111.05\n",
      "converged:                       True   LL-Null:                       -119.67\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001813\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8619      0.216      8.633      0.000       1.439       2.285\n",
      "x2            -0.4796      0.186     -2.582      0.010      -0.844      -0.116\n",
      "x1             1.2251      0.403      3.042      0.002       0.436       2.014\n",
      "==============================================================================\n",
      "\n",
      "# Denominator Model (Previous Treatment = 1)\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           censored_inv   No. Observations:                  339\n",
      "Model:                          Logit   Df Residuals:                      336\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 08 Mar 2025   Pseudo R-squ.:                 0.02073\n",
      "Time:                        21:27:38   Log-Likelihood:                -79.751\n",
      "converged:                       True   LL-Null:                       -81.439\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1849\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6243      0.268      9.784      0.000       2.099       3.150\n",
      "x2            -0.3895      0.211     -1.847      0.065      -0.803       0.024\n",
      "x1            -0.0203      0.479     -0.042      0.966      -0.959       0.918\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "trial_itt.show_weight_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Specify Outcome Model\n",
    "Now we can specify the outcome model. Here we can include adjustment terms for any variables in the dataset. The numerator terms from the stabilised weight models are automatically included in the outcome model formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5\n",
    "def set_outcome_model(self, adjustment_terms=None, model_fitter=None):\n",
    "    if self.data is None:\n",
    "        raise ValueError(\"set_data() before defining the outcome model.\")\n",
    "\n",
    "    # Determine treatment variable\n",
    "    treatment_var = \"treatment\"\n",
    "\n",
    "    # Extract stabilized weight terms\n",
    "    stabilised_weight_terms = []\n",
    "    if self.switch_weights:\n",
    "        stabilised_weight_terms.append(self.switch_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "    if self.censor_weights:\n",
    "        stabilised_weight_terms.append(self.censor_weights[\"numerator\"].split(\"~\")[1].strip())\n",
    "\n",
    "    stabilised_weight_terms = \" + \".join(stabilised_weight_terms) if stabilised_weight_terms else \"1\"\n",
    "\n",
    "    # Default adjustment terms based on estimand\n",
    "    if adjustment_terms is None:\n",
    "        adjustment_terms = [\"x1\", \"x2\", \"x3\", \"age\"] if self.estimand == \"PP\" else [\"x2\"]\n",
    "    elif isinstance(adjustment_terms, str):\n",
    "        adjustment_terms = adjustment_terms.split(\" + \")\n",
    "\n",
    "    # Polynomial terms for time effects\n",
    "    additional_terms = []\n",
    "    if \"followup_time\" in self.data.columns:\n",
    "        self.data[\"followup_time_squared\"] = self.data[\"followup_time\"] ** 2\n",
    "        additional_terms.extend([\"followup_time\", \"followup_time_squared\"])\n",
    "\n",
    "    # Ensure 'period' and its squared term are included\n",
    "    if \"period\" in self.data.columns:\n",
    "        self.data[\"period_squared\"] = self.data[\"period\"] ** 2\n",
    "        additional_terms.extend([\"period\", \"period_squared\"])\n",
    "\n",
    "    # Ensure unique terms using a set\n",
    "    all_terms = set([treatment_var] + adjustment_terms + additional_terms)\n",
    "    stabilised_terms = set(stabilised_weight_terms.split(\" + \"))  # Convert to set\n",
    "\n",
    "    # Merge while keeping unique terms\n",
    "    final_terms = all_terms | stabilised_terms\n",
    "    final_terms.discard(\"1\")  # Remove placeholder \"1\" if present\n",
    "\n",
    "    # Construct formula\n",
    "    formula = \"outcome ~ \" + \" + \".join(sorted(final_terms))  # Sort for consistency\n",
    "\n",
    "    # Ensure weights exist\n",
    "    if \"final_weight\" not in self.data.columns:\n",
    "        raise ValueError(\"Weights have not been calculated. Run calculate_weights() first.\")\n",
    "\n",
    "    # Default to logistic regression model fitter if none is provided\n",
    "    if model_fitter is None:\n",
    "        model_fitter = stats_glm_logit(save_path=None)\n",
    "\n",
    "    # Store in outcome_model dictionary\n",
    "    self.outcome_model = {\n",
    "        \"formula\": formula,\n",
    "        \"treatment_var\": treatment_var,\n",
    "        \"adjustment_vars\": list(all_terms),  # Store as list for consistency\n",
    "        \"stabilised_weights_terms\": \" + \".join(sorted(stabilised_terms)),  # Keep as string for logging\n",
    "        \"model_fitter\": model_fitter,\n",
    "        \"fitted\": None  # Will be used in Step 8 (fit_msm)\n",
    "    }\n",
    "\n",
    "    return self\n",
    "\n",
    "def show_outcome_model(self):\n",
    "    return self.outcome_model if self.outcome_model else \"Not calculated\"\n",
    "\n",
    "TrialSequence.set_outcome_model = set_outcome_model\n",
    "TrialSequence.show_outcome_model = show_outcome_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': 'outcome ~ age + followup_time + followup_time_squared + period + period_squared + treatment + x1 + x2 + x3',\n",
       " 'treatment_var': 'treatment',\n",
       " 'adjustment_vars': ['x3',\n",
       "  'x1',\n",
       "  'followup_time',\n",
       "  'age',\n",
       "  'treatment',\n",
       "  'x2',\n",
       "  'followup_time_squared',\n",
       "  'period_squared',\n",
       "  'period'],\n",
       " 'stabilised_weights_terms': 'age + x2',\n",
       " 'model_fitter': <function __main__.stats_glm_logit.<locals>.fit_model(numerator, denominator, data)>,\n",
       " 'fitted': None}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_pp.set_outcome_model()  \n",
    "trial_itt.set_outcome_model(adjustment_terms=\"x2\")  \n",
    "trial_pp.show_outcome_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expand Trials\n",
    "Now we are ready to create the data set with all of the sequence of target trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_expansion_options(self, output: TEDatastore, chunk_size: int = 0, first_period: int = 0, last_period: float = float('inf'), censor_at_switch: bool = False):\n",
    "    \n",
    "    self.expansion = TEExpansion(chunk_size = chunk_size, datastore = output, first_period = first_period, last_period = last_period, censor_at_switch = censor_at_switch)\n",
    "\n",
    "    return self\n",
    "\n",
    "TrialSequence.set_expansion_options = set_expansion_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrialSequenceITT at 0x29739761400>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = TEDatastore()\n",
    "trial_pp.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = True)\n",
    "trial_itt.set_expansion_options(output, chunk_size=500, first_period = 0, last_period= float('inf'), censor_at_switch = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Create Sequence of Trials Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_trials(self):\n",
    "    data = self.data.copy()\n",
    "    outcome_adj_vars = self.get_outcome_adjustment_vars()\n",
    "    keeplist = list(set(['id', 'trial_period', 'followup_time', 'outcome', 'weight', 'treatment', 'x2', 'age'] + outcome_adj_vars))\n",
    "\n",
    "    if 'wt' not in data.columns:\n",
    "        data['wt'] = 1\n",
    "\n",
    "    all_ids = data['id'].unique()\n",
    "    if self.expansion.chunk_size == 0:\n",
    "        ids_split = [all_ids]\n",
    "    else:\n",
    "        ids_split = np.array_split(all_ids, np.ceil(len(all_ids) / self.expansion.chunk_size))\n",
    "\n",
    "    for ids in ids_split:\n",
    "        switch_data = self._expand_chunk(data, ids, outcome_adj_vars, keeplist)\n",
    "        self.expansion.datastore = self.expansion.datastore.save_expanded_data(switch_data)\n",
    "\n",
    "    return self\n",
    "\n",
    "def _expand_chunk(self, data: pd.DataFrame, ids: np.ndarray, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "    chunk_data = data[data['id'].isin(ids)].copy()\n",
    "\n",
    "    first_period = max([self.expansion.first_period, chunk_data[chunk_data['eligible'] == 1]['period'].min() or self.expansion.first_period])\n",
    "    last_period = min([self.expansion.last_period, chunk_data[chunk_data['eligible'] == 1]['period'].max() or self.expansion.last_period])\n",
    "    \n",
    "    expanded_data = []\n",
    "    for _, row in chunk_data.iterrows():\n",
    "        if row['eligible'] == 1 and first_period <= row['period'] <= last_period:\n",
    "            trial_start = row['period']\n",
    "            trial_data = self._generate_trial_instance(row, chunk_data, trial_start, last_period, outcome_adj_vars, keeplist)\n",
    "            expanded_data.append(trial_data)\n",
    "\n",
    "    result = pd.concat(expanded_data, ignore_index=True) if expanded_data else pd.DataFrame()\n",
    "\n",
    "    return result[keeplist]\n",
    "\n",
    "def _generate_trial_instance(self, baseline_row: pd.Series, data: pd.DataFrame, trial_start: int, last_period: float, outcome_adj_vars: List[str], keeplist: List[str]):\n",
    "\n",
    "    id_val = baseline_row['id']\n",
    "    patient_data = data[data['id'] == id_val].sort_values('period')\n",
    "    rows = []\n",
    "\n",
    "    if pd.isna(last_period) or last_period == float('inf'):\n",
    "        last_period_value = patient_data['period'].max()\n",
    "    else:\n",
    "        last_period_value = last_period\n",
    "\n",
    "    # Convert float to integer to handle errors\n",
    "    if pd.notna(last_period_value):\n",
    "        last_period_int = int(np.floor(float(last_period_value)))\n",
    "    else:\n",
    "        last_period_int = int(trial_start)\n",
    "\n",
    "    max_period_value = patient_data['period'].max()\n",
    "    if pd.notna(max_period_value):\n",
    "        max_period = int(np.floor(float(max_period_value)))\n",
    "    else:\n",
    "        max_period = last_period_int \n",
    "\n",
    "    last_period_int = int(last_period_int)\n",
    "    max_period = int(max_period)\n",
    "\n",
    "    for period in range(int(trial_start), int(min(last_period_int + 1, max_period + 1))):\n",
    "        period_row = patient_data[patient_data['period'] == period].iloc[0] if not patient_data[patient_data['period'] == period].empty else None\n",
    "        \n",
    "        if period_row is None:\n",
    "            continue\n",
    "\n",
    "        if self.expansion.censor_at_switch and period > trial_start:\n",
    "            prev_row = patient_data[patient_data['period'] == (period - 1)].iloc[0]\n",
    "            if prev_row['treatment'] != period_row['treatment']:\n",
    "                break  # Censor at switch\n",
    "\n",
    "        trial_period = period - trial_start\n",
    "        followup_time = period - trial_start\n",
    "        final_weight = self.data[(self.data['id'] == id_val) & (self.data['period'] == period)]['final_weight'].iloc[0] if not self.data[(self.data['id'] == id_val) & (self.data['period'] == period)].empty else 1.0\n",
    "        row_dict = {\n",
    "            'id': id_val,\n",
    "            'trial_period': trial_period,\n",
    "            'followup_time': followup_time,\n",
    "            'outcome': period_row['outcome'],\n",
    "            'weight': final_weight,  \n",
    "            'treatment': period_row['treatment'],\n",
    "        }\n",
    "        \n",
    "        for var in outcome_adj_vars + ['age', 'x2']:\n",
    "            if var in patient_data.columns:\n",
    "                row_dict[var] = period_row.get(var, np.nan)\n",
    "            else:\n",
    "                row_dict[var] = np.nan \n",
    "\n",
    "        rows.append(pd.Series(row_dict))\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    int_columns = ['id', 'trial_period', 'followup_time', 'outcome', 'treatment', 'age']\n",
    "    df[int_columns] = df[int_columns].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_outcome_adjustment_vars(self):\n",
    "    return getattr(self.outcome_model, 'adjustment_vars', [])\n",
    "\n",
    "\n",
    "TrialSequence.expand_trials = expand_trials\n",
    "TrialSequence._expand_chunk = _expand_chunk\n",
    "TrialSequence._generate_trial_instance = _generate_trial_instance\n",
    "TrialSequence.get_outcome_adjustment_vars = get_outcome_adjustment_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanded Data:\n",
      "     followup_time  age  trial_period  id  treatment        x2  outcome  \\\n",
      "0                0   36             0   1          1  1.146148        0   \n",
      "1                1   37             1   1          1  0.002200        0   \n",
      "2                2   38             2   1          1 -0.481762        0   \n",
      "3                3   39             3   1          1  0.007872        0   \n",
      "4                4   40             4   1          1  0.216054        0   \n",
      "..             ...  ...           ...  ..        ...       ...      ...   \n",
      "995              0   64             0  98          1  1.392339        0   \n",
      "996              1   65             1  98          1 -0.934798        0   \n",
      "997              2   66             2  98          1 -0.735241        0   \n",
      "998              0   65             0  99          1 -0.346378        0   \n",
      "999              1   66             1  99          1 -1.106481        0   \n",
      "\n",
      "       weight  \n",
      "0    1.792166  \n",
      "1    1.508792  \n",
      "2    1.788880  \n",
      "3    1.823548  \n",
      "4    1.542038  \n",
      "..        ...  \n",
      "995  1.161473  \n",
      "996  1.056842  \n",
      "997  1.062165  \n",
      "998  1.074015  \n",
      "999  1.052628  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "trial_pp.expand_trials()\n",
    "trial_itt.expand_trials()\n",
    "print(\"\\nExpanded Data:\")\n",
    "print(trial_itt.expansion.datastore.data)\n",
    "trial_pp.expansion.datastore.data.to_csv(\"outputfor_pp.csv\", index=False)\n",
    "trial_itt.expansion.datastore.data.to_csv(\"outputfor_itt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load or Sample Expanded Data\n",
    "Now that the expanded data has been created, we can prepare the data to fit the outcome model. For data that can fit comfortably in memory, this is a trivial step using load_expanded_data.\n",
    "\n",
    "For large datasets, it may be necessary to sample from the expanded by setting the p_control argument. This sets the probability that an observation with outcome == 0 will be included in the loaded data. A seed can be set for reproducibility. Additionally, a vector of periods to include can be specified, e.g., period = 1:60, and/or a subsetting condition, subset_condition = \"age > 65\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expanded_data(self, p_control: Optional[float] = None, period: Optional[List[int]] = None, subset_condition: Optional[str] = None, seed: Optional[int] = None):\n",
    "    \n",
    "    if p_control is None:\n",
    "        data_table = self.expansion.datastore.data.copy()\n",
    "        data_table['sample_weight'] = 1\n",
    "    else:\n",
    "        np.random.seed(seed) if seed is not None else np.random.seed()\n",
    "        data_table = self.expansion.datastore.data.copy()\n",
    "\n",
    "        mask_outcome_1 = data_table['outcome'] == 1\n",
    "        mask_outcome_0 = data_table['outcome'] == 0\n",
    "        sampled_0 = data_table[mask_outcome_0].sample(frac=p_control, replace=False)\n",
    "        data_table = pd.concat([data_table[mask_outcome_1], sampled_0])\n",
    "\n",
    "        data_table.loc[mask_outcome_0, 'sample_weight'] = 1 / p_control if p_control > 0 else 1\n",
    "        data_table.loc[mask_outcome_1, 'sample_weight'] = 1\n",
    "\n",
    "    if period is not None:\n",
    "        data_table = data_table[data_table['trial_period'].isin(period) | data_table['followup_time'].isin(period)]\n",
    "    \n",
    "    if subset_condition is not None:\n",
    "        data_table = data_table.query(subset_condition)\n",
    "    \n",
    "    data_table = data_table.sort_values(['id', 'trial_period', 'followup_time'])\n",
    "    data_table = data_table.reset_index(drop=True)\n",
    "    \n",
    "    self.outcome_data = data_table\n",
    "    \n",
    "    return self\n",
    "\n",
    "TrialSequence.load_expanded_data = load_expanded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in self.outcome_data: ['followup_time', 'age', 'trial_period', 'id', 'treatment', 'x2', 'outcome', 'weight', 'sample_weight']\n"
     ]
    }
   ],
   "source": [
    "trial_pp.load_expanded_data(p_control = 0.5, seed=1234)\n",
    "trial_itt.load_expanded_data(p_control = 0.5, seed=1234)\n",
    "print(\"Columns in self.outcome_data:\", trial_itt.outcome_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Fit Marginal Structural Model\n",
    "To fit the outcome model we use fit_msm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_msm(self, weight_cols=[\"weight\"], modify_weights=None, family=\"binomial\"):\n",
    "    if not self.outcome_model:\n",
    "        raise ValueError(\"Outcome model not defined. Run set_outcome_model() first.\")\n",
    "    \n",
    "    formula = self.outcome_model[\"formula\"]\n",
    "    print(f\"Using formula from set_outcome_model: {formula}\")\n",
    "    \n",
    "    weight_col = next(col for col in weight_cols if col in self.outcome_data.columns)\n",
    "    data = self.outcome_data[~self.outcome_data[weight_col].isna()].copy()\n",
    "    weights = data[weight_col].values\n",
    "    \n",
    "    if modify_weights:\n",
    "        weights = modify_weights(weights)\n",
    "    \n",
    "    # Fit the MSM\n",
    "    try:\n",
    "        if family == \"binomial\":\n",
    "            model = smf.logit(formula, data=data)\n",
    "            fitted_model = model.fit(method='lbfgs', weights=weights, disp=0, maxiter=100)\n",
    "        elif family == \"gaussian\":\n",
    "            model = smf.ols(formula, data=data, weights=weights)\n",
    "            fitted_model = model.fit()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported family. Use 'binomial' or 'gaussian'.\")\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        raise ValueError(f\"Model fitting failed due to singular matrix: {e}.\")\n",
    "    \n",
    "    print(\"MSM Fit Summary:\")\n",
    "    print(fitted_model.summary())\n",
    "    self.outcome_model[\"fitted\"] = fitted_model\n",
    "    return fitted_model\n",
    "\n",
    "TrialSequence.fit_msm = fit_msm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using formula from set_outcome_model: outcome ~ followup_time + followup_time_squared + period + period_squared + treatment + x2\n"
     ]
    },
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'followup_time_squared' is not defined\n    outcome ~ followup_time + followup_time_squared + period + period_squared + treatment + x2\n                              ^^^^^^^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\compat.py:40\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\eval.py:179\u001b[0m, in \u001b[0;36mEvalEnvironment.eval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    178\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcompile\u001b[39m(expr, source_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVarLookupDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minner_namespace\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_namespaces\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'followup_time_squared' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[244], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwinsorize_weights\u001b[39m(weights):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#99th percentile values\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mminimum(weights, np\u001b[38;5;241m.\u001b[39mquantile(weights, \u001b[38;5;241m0.99\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrial_itt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_msm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodify_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwinsorize_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[225], line 130\u001b[0m, in \u001b[0;36mTrialSequence.fit_msm\u001b[1;34m(self, weight_cols, modify_weights, family)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 130\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m         fitted_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, weights\u001b[38;5;241m=\u001b[39mweights, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\base\\model.py:203\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# with patsy it's drop or raise. let's raise.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 203\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_formula_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m ((endog, exog), missing_idx, design_info) \u001b[38;5;241m=\u001b[39m tmp\n\u001b[0;32m    206\u001b[0m max_endog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_formula_max_endog\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\formula\\formulatools.py:63\u001b[0m, in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_util\u001b[38;5;241m.\u001b[39m_is_using_pandas(Y, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 63\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mdmatrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m         result \u001b[38;5;241m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     67\u001b[0m                            NA_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\highlevel.py:319\u001b[0m, in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    318\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 319\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m \u001b[43m_do_highlevel_design\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is missing required outcome variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_iter_maker\u001b[39m():\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m([data])\n\u001b[1;32m--> 164\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m \u001b[43m_try_incr_builders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_design_matrices(\n\u001b[0;32m    169\u001b[0m         design_infos, data, NA_action\u001b[38;5;241m=\u001b[39mNA_action, return_type\u001b[38;5;241m=\u001b[39mreturn_type\n\u001b[0;32m    170\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\highlevel.py:56\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdesign_matrix_builders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs_termlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs_termlist\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\build.py:746\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    743\u001b[0m factor_states \u001b[38;5;241m=\u001b[39m _factors_memorize(all_factors, data_iter_maker, eval_env)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;66;03m# Now all the factors have working eval methods, so we can evaluate them\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# on some data to find out what type of data they return.\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m (num_column_counts, cat_levels_contrasts) \u001b[38;5;241m=\u001b[39m \u001b[43m_examine_factor_types\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Now we need the factor infos, which encapsulate the knowledge of\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# how to turn any given factor into a chunk of data:\u001b[39;00m\n\u001b[0;32m    751\u001b[0m factor_infos \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\build.py:491\u001b[0m, in \u001b[0;36m_examine_factor_types\u001b[1;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_iter_maker():\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(examine_needed):\n\u001b[1;32m--> 491\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mfactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m cat_sniffers \u001b[38;5;129;01mor\u001b[39;00m guess_categorical(value):\n\u001b[0;32m    493\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m factor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_sniffers:\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\eval.py:599\u001b[0m, in \u001b[0;36mEvalFactor.eval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, memorize_state, data):\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\eval.py:582\u001b[0m, in \u001b[0;36mEvalFactor._eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m, code, memorize_state, data):\n\u001b[0;32m    581\u001b[0m     inner_namespace \u001b[38;5;241m=\u001b[39m VarLookupDict([data, memorize_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_and_wrap_exc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError evaluating factor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_namespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cedric\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\patsy\\compat.py:43\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     42\u001b[0m     new_exc \u001b[38;5;241m=\u001b[39m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (msg, e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e), origin)\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'followup_time_squared' is not defined\n    outcome ~ followup_time + followup_time_squared + period + period_squared + treatment + x2\n                              ^^^^^^^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "def winsorize_weights(weights):\n",
    "    #99th percentile values\n",
    "    return np.minimum(weights, np.quantile(weights, 0.99, method='nearest'))\n",
    "\n",
    "trial_itt.fit_msm(weight_cols=[\"weight\"], modify_weights=winsorize_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Inference\n",
    "We use the predict() method to estimate survival probabilities or cumulative incidences for different values of assigned_treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, newdata=None, predict_times=None, type=\"survival\", confidence_level=0.95):\n",
    "    \n",
    "    if not self.outcome_model or self.outcome_model[\"fitted\"] is None:\n",
    "        raise ValueError(\"MSM not fitted. Run fit_msm() first.\")\n",
    "    \n",
    "    # Use outcome_data if newdata is not provided\n",
    "    if newdata is None:\n",
    "        if self.outcome_data is None:\n",
    "            raise ValueError(\"outcome_data not available. Run load_expanded_data() first.\")\n",
    "        newdata = self.outcome_data[self.outcome_data[\"trial_period\"] == 1].copy()\n",
    "    else:\n",
    "        newdata = newdata[newdata[\"trial_period\"] == 1].copy()\n",
    "    \n",
    "    # Default predict_times if not specified\n",
    "    if predict_times is None:\n",
    "        predict_times = np.arange(0, 11)\n",
    "    \n",
    "    # Ensure predict_times are integers and within data range\n",
    "    predict_times = np.array(predict_times, dtype=int)\n",
    "    max_time = newdata[\"followup_time\"].max()\n",
    "    predict_times = predict_times[predict_times <= max_time]\n",
    "    \n",
    "    # Extract fitted model\n",
    "    fitted_model = self.outcome_model[\"fitted\"]\n",
    "    \n",
    "    # Prepare data for prediction\n",
    "    prediction_data = []\n",
    "    treatment_values = [0, 1]  # Assume binary treatment\n",
    "    for time in predict_times:\n",
    "        for treatment in treatment_values:\n",
    "            temp_data = newdata.copy()\n",
    "            temp_data[\"followup_time\"] = time\n",
    "            temp_data[\"treatment\"] = treatment\n",
    "            # Update other time-dependent terms if needed (e.g., period, period_squared)\n",
    "            temp_data[\"period\"] = time + 1  # Adjust based on your data structure\n",
    "            temp_data[\"period_squared\"] = temp_data[\"period\"] ** 2\n",
    "            temp_data[\"followup_time_squared\"] = temp_data[\"followup_time\"] ** 2\n",
    "            \n",
    "            # Predict probabilities\n",
    "            pred_prob = fitted_model.predict(temp_data)\n",
    "            prediction_data.append({\n",
    "                \"followup_time\": time,\n",
    "                \"treatment\": treatment,\n",
    "                \"predicted_prob\": pred_prob.mean()  # Average over individuals\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    pred_df = pd.DataFrame(prediction_data)\n",
    "    \n",
    "    # Calculate survival (1 - cumulative probability, approximated)\n",
    "    # Note: This is a simplification; true survival requires time-to-event modeling\n",
    "    pred_df[\"survival\"] = 1 - pred_df[\"predicted_prob\"]\n",
    "    \n",
    "    # Group by time for treatment 0 and 1\n",
    "    surv_0 = pred_df[pred_df[\"treatment\"] == 0].set_index(\"followup_time\")[\"survival\"]\n",
    "    surv_1 = pred_df[pred_df[\"treatment\"] == 1].set_index(\"followup_time\")[\"survival\"]\n",
    "    \n",
    "    # Calculate difference and confidence intervals\n",
    "    difference = surv_1 - surv_0\n",
    "    conf_int = fitted_model.conf_int(alpha=1 - confidence_level)\n",
    "    # Approximate CI for difference (simplified; actual CI requires bootstrapping or delta method)\n",
    "    se = np.sqrt((fitted_model.bse ** 2).sum())  # Rough standard error approximation\n",
    "    z_score = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "    ci_lower = difference - z_score * se\n",
    "    ci_upper = difference + z_score * se\n",
    "    \n",
    "    result = {\n",
    "        \"survival\": {\n",
    "            \"followup_time\": surv_0.index,\n",
    "            \"treatment_0\": surv_0.values,\n",
    "            \"treatment_1\": surv_1.values\n",
    "        },\n",
    "        \"difference\": {\n",
    "            \"followup_time\": difference.index,\n",
    "            \"survival_diff\": difference.values,\n",
    "            f\"{int(100 * (1 - confidence_level) / 2)}%\": ci_lower,\n",
    "            f\"{int(100 * (1 + confidence_level))}%\": ci_upper\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if type == \"difference\":\n",
    "        return result[\"difference\"]\n",
    "    return result\n",
    "\n",
    "TrialSequence.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trial_itt.predict()\n",
    "diff_data = preds[\"difference\"]\n",
    "plt.plot(diff_data[\"followup_time\"], diff_data[\"survival_diff\"], label=\"Survival Difference\")\n",
    "plt.plot(diff_data[\"followup_time\"], diff_data[\"2%\"], \"r--\", label=\"95% CI\")\n",
    "plt.plot(diff_data[\"followup_time\"], diff_data[\"195%\"], \"r--\")\n",
    "plt.xlabel(\"Follow up\")\n",
    "plt.ylabel(\"Survival difference\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
